<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN"
  "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">


<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    
    <title>Server maintenance &mdash; swift 2.12.1.dev102 documentation</title>
    
    <link rel="stylesheet" href="../_static/nature.css" type="text/css" />
    <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
    <link rel="stylesheet" href="../_static/tweaks.css" type="text/css" />
    
    <script type="text/javascript">
      var DOCUMENTATION_OPTIONS = {
        URL_ROOT:    '../',
        VERSION:     '2.12.1.dev102',
        COLLAPSE_INDEX: false,
        FILE_SUFFIX: '.html',
        HAS_SOURCE:  true
      };
    </script>
    <script type="text/javascript" src="../_static/jquery.js"></script>
    <script type="text/javascript" src="../_static/underscore.js"></script>
    <script type="text/javascript" src="../_static/doctools.js"></script>
    <link rel="top" title="swift 2.12.1.dev102 documentation" href="../index.html" />
    <link rel="up" title="Swift Ops Runbook" href="index.html" />
    <link rel="next" title="Troubleshooting tips" href="troubleshooting.html" />
    <link rel="prev" title="Software configuration procedures" href="procedures.html" /> 
  </head>
  <body role="document">
  <div id="header">
    <h1 id="logo"><a href="http://www.openstack.org/">OpenStack</a></h1>
    <ul id="navigation">
      
      <li><a href="http://www.openstack.org/" title="Go to the Home page" class="link">Home</a></li>
      <li><a href="http://www.openstack.org/projects/" title="Go to the OpenStack Projects page">Projects</a></li>
      <li><a href="http://www.openstack.org/user-stories/" title="Go to the User Stories page" class="link">User Stories</a></li>
      <li><a href="http://www.openstack.org/community/" title="Go to the Community page" class="link">Community</a></li>
      <li><a href="http://www.openstack.org/blog/" title="Go to the OpenStack Blog">Blog</a></li>
      <li><a href="http://wiki.openstack.org/" title="Go to the OpenStack Wiki">Wiki</a></li>
      <li><a href="http://docs.openstack.org/" title="Go to OpenStack Documentation" class="current">Documentation</a></li>
      
    </ul>
  </div>
  

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          <div class="body" role="main">
            
  <div class="section" id="server-maintenance">
<h1>Server maintenance<a class="headerlink" href="#server-maintenance" title="Permalink to this headline">¶</a></h1>
<div class="section" id="general-assumptions">
<h2>General assumptions<a class="headerlink" href="#general-assumptions" title="Permalink to this headline">¶</a></h2>
<ul class="simple">
<li>It is assumed that anyone attempting to replace hardware components
will have already read and understood the appropriate maintenance and
service guides.</li>
<li>It is assumed that where servers need to be taken off-line for
hardware replacement, that this will be done in series, bringing the
server back on-line before taking the next off-line.</li>
<li>It is assumed that the operations directed procedure will be used for
identifying hardware for replacement.</li>
</ul>
</div>
<div class="section" id="assessing-the-health-of-swift">
<h2>Assessing the health of swift<a class="headerlink" href="#assessing-the-health-of-swift" title="Permalink to this headline">¶</a></h2>
<p>You can run the swift-recon tool on a Swift proxy node to get a quick
check of how Swift is doing. Please note that the numbers below are
necessarily somewhat subjective. Sometimes parameters for which we
say &#8216;low values are good&#8217; will have pretty high values for a time. Often
if you wait a while things get better.</p>
<p>For example:</p>
<div class="code highlight-python"><div class="highlight"><pre><span></span>sudo swift-recon -rla
===============================================================================
[2012-03-10 12:57:21] Checking async pendings on 384 hosts...
Async stats: low: 0, high: 1, avg: 0, total: 1
===============================================================================

[2012-03-10 12:57:22] Checking replication times on 384 hosts...
[Replication Times] shortest: 1.4113877813, longest: 36.8293570836, avg: 4.86278064749
===============================================================================

[2012-03-10 12:57:22] Checking load avg&#39;s on 384 hosts...
[5m load average] lowest: 2.22, highest: 9.5, avg: 4.59578125
[15m load average] lowest: 2.36, highest: 9.45, avg: 4.62622395833
[1m load average] lowest: 1.84, highest: 9.57, avg: 4.5696875
===============================================================================
</pre></div>
</div>
<p>In the example above we ask for information on replication times (-r),
load averages (-l) and async pendings (-a). This is a healthy Swift
system. Rules-of-thumb for &#8216;good&#8217; recon output are:</p>
<ul>
<li><p class="first">Nodes that respond are up and running Swift. If all nodes respond,
that is a good sign. But some nodes may time out. For example:</p>
<div class="code highlight-python"><div class="highlight"><pre><span></span>-&gt; [http://&lt;redacted&gt;.29:6200/recon/load:] &lt;urlopen error [Errno 111] ECONNREFUSED&gt;
-&gt; [http://&lt;redacted&gt;.31:6200/recon/load:] &lt;urlopen error timed out&gt;
</pre></div>
</div>
</li>
<li><p class="first">That could be okay or could require investigation.</p>
</li>
<li><p class="first">Low values (say &lt; 10 for high and average) for async pendings are
good. Higher values occur when disks are down and/or when the system
is heavily loaded. Many simultaneous PUTs to the same container can
drive async pendings up. This may be normal, and may resolve itself
after a while. If it persists, one way to track down the problem is
to find a node with high async pendings (with <code class="docutils literal"><span class="pre">swift-recon</span> <span class="pre">-av</span> <span class="pre">|</span> <span class="pre">sort</span>
<span class="pre">-n</span> <span class="pre">-k4</span></code>), then check its Swift logs, Often async pendings are high
because a node cannot write to a container on another node. Often
this is because the node or disk is offline or bad. This may be okay
if we know about it.</p>
</li>
<li><p class="first">Low values for replication times are good. These values rise when new
rings are pushed, and when nodes and devices are brought back on
line.</p>
</li>
<li><p class="first">Our &#8216;high&#8217; load average values are typically in the 9-15 range. If
they are a lot bigger it is worth having a look at the systems
pushing the average up. Run <code class="docutils literal"><span class="pre">swift-recon</span> <span class="pre">-av</span></code> to get the individual
averages. To sort the entries with the highest at the end,
run <code class="docutils literal"><span class="pre">swift-recon</span> <span class="pre">-av</span> <span class="pre">|</span> <span class="pre">sort</span> <span class="pre">-n</span> <span class="pre">-k4</span></code>.</p>
</li>
</ul>
<p>For comparison here is the recon output for the same system above when
two entire racks of Swift are down:</p>
<div class="code highlight-python"><div class="highlight"><pre><span></span>[2012-03-10 16:56:33] Checking async pendings on 384 hosts...
-&gt; http://&lt;redacted&gt;.22:6200/recon/async: &lt;urlopen error timed out&gt;
-&gt; http://&lt;redacted&gt;.18:6200/recon/async: &lt;urlopen error timed out&gt;
-&gt; http://&lt;redacted&gt;.16:6200/recon/async: &lt;urlopen error timed out&gt;
-&gt; http://&lt;redacted&gt;.13:6200/recon/async: &lt;urlopen error timed out&gt;
-&gt; http://&lt;redacted&gt;.30:6200/recon/async: &lt;urlopen error timed out&gt;
-&gt; http://&lt;redacted&gt;.6:6200/recon/async: &lt;urlopen error timed out&gt;
.........
-&gt; http://&lt;redacted&gt;.5:6200/recon/async: &lt;urlopen error timed out&gt;
-&gt; http://&lt;redacted&gt;.15:6200/recon/async: &lt;urlopen error timed out&gt;
-&gt; http://&lt;redacted&gt;.9:6200/recon/async: &lt;urlopen error timed out&gt;
-&gt; http://&lt;redacted&gt;.27:6200/recon/async: &lt;urlopen error timed out&gt;
-&gt; http://&lt;redacted&gt;.4:6200/recon/async: &lt;urlopen error timed out&gt;
-&gt; http://&lt;redacted&gt;.8:6200/recon/async: &lt;urlopen error timed out&gt;
Async stats: low: 243, high: 659, avg: 413, total: 132275
===============================================================================
[2012-03-10 16:57:48] Checking replication times on 384 hosts...
-&gt; http://&lt;redacted&gt;.22:6200/recon/replication: &lt;urlopen error timed out&gt;
-&gt; http://&lt;redacted&gt;.18:6200/recon/replication: &lt;urlopen error timed out&gt;
-&gt; http://&lt;redacted&gt;.16:6200/recon/replication: &lt;urlopen error timed out&gt;
-&gt; http://&lt;redacted&gt;.13:6200/recon/replication: &lt;urlopen error timed out&gt;
-&gt; http://&lt;redacted&gt;.30:6200/recon/replication: &lt;urlopen error timed out&gt;
-&gt; http://&lt;redacted&gt;.6:6200/recon/replication: &lt;urlopen error timed out&gt;
............
-&gt; http://&lt;redacted&gt;.5:6200/recon/replication: &lt;urlopen error timed out&gt;
-&gt; http://&lt;redacted&gt;.15:6200/recon/replication: &lt;urlopen error timed out&gt;
-&gt; http://&lt;redacted&gt;.9:6200/recon/replication: &lt;urlopen error timed out&gt;
-&gt; http://&lt;redacted&gt;.27:6200/recon/replication: &lt;urlopen error timed out&gt;
-&gt; http://&lt;redacted&gt;.4:6200/recon/replication: &lt;urlopen error timed out&gt;
-&gt; http://&lt;redacted&gt;.8:6200/recon/replication: &lt;urlopen error timed out&gt;
[Replication Times] shortest: 1.38144306739, longest: 112.620954418, avg: 10.285
9475361
===============================================================================
[2012-03-10 16:59:03] Checking load avg&#39;s on 384 hosts...
-&gt; http://&lt;redacted&gt;.22:6200/recon/load: &lt;urlopen error timed out&gt;
-&gt; http://&lt;redacted&gt;.18:6200/recon/load: &lt;urlopen error timed out&gt;
-&gt; http://&lt;redacted&gt;.16:6200/recon/load: &lt;urlopen error timed out&gt;
-&gt; http://&lt;redacted&gt;.13:6200/recon/load: &lt;urlopen error timed out&gt;
-&gt; http://&lt;redacted&gt;.30:6200/recon/load: &lt;urlopen error timed out&gt;
-&gt; http://&lt;redacted&gt;.6:6200/recon/load: &lt;urlopen error timed out&gt;
............
-&gt; http://&lt;redacted&gt;.15:6200/recon/load: &lt;urlopen error timed out&gt;
-&gt; http://&lt;redacted&gt;.9:6200/recon/load: &lt;urlopen error timed out&gt;
-&gt; http://&lt;redacted&gt;.27:6200/recon/load: &lt;urlopen error timed out&gt;
-&gt; http://&lt;redacted&gt;.4:6200/recon/load: &lt;urlopen error timed out&gt;
-&gt; http://&lt;redacted&gt;.8:6200/recon/load: &lt;urlopen error timed out&gt;
[5m load average] lowest: 1.71, highest: 4.91, avg: 2.486375
[15m load average] lowest: 1.79, highest: 5.04, avg: 2.506125
[1m load average] lowest: 1.46, highest: 4.55, avg: 2.4929375
===============================================================================
</pre></div>
</div>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p class="last">The replication times and load averages are within reasonable
parameters, even with 80 object stores down. Async pendings, however is
quite high. This is due to the fact that the containers on the servers
which are down cannot be updated. When those servers come back up, async
pendings should drop. If async pendings were at this level without an
explanation, we have a problem.</p>
</div>
</div>
<div class="section" id="recon-examples">
<h2>Recon examples<a class="headerlink" href="#recon-examples" title="Permalink to this headline">¶</a></h2>
<p>Here is an example of noting and tracking down a problem with recon.</p>
<p>Running reccon shows some async pendings:</p>
<div class="code highlight-python"><div class="highlight"><pre><span></span>bob@notso:~/swift-1.4.4/swift$ ssh -q &lt;redacted&gt;.132.7 sudo swift-recon -alr
===============================================================================
[2012-03-14 17:25:55] Checking async pendings on 384 hosts...
Async stats: low: 0, high: 23, avg: 8, total: 3356
===============================================================================
[2012-03-14 17:25:55] Checking replication times on 384 hosts...
[Replication Times] shortest: 1.49303831657, longest: 39.6982825994, avg: 4.2418222066
===============================================================================
[2012-03-14 17:25:56] Checking load avg&#39;s on 384 hosts...
[5m load average] lowest: 2.35, highest: 8.88, avg: 4.45911458333
[15m load average] lowest: 2.41, highest: 9.11, avg: 4.504765625
[1m load average] lowest: 1.95, highest: 8.56, avg: 4.40588541667
 ===============================================================================
</pre></div>
</div>
<p>Why? Running recon again with -av swift (not shown here) tells us that
the node with the highest (23) is &lt;redacted&gt;.72.61. Looking at the log
files on &lt;redacted&gt;.72.61 we see:</p>
<div class="code highlight-python"><div class="highlight"><pre><span></span>souzab@&lt;redacted&gt;:~$ sudo tail -f /var/log/swift/background.log | - grep -i ERROR
Mar 14 17:28:06 &lt;redacted&gt; container-replicator ERROR Remote drive not mounted
{&#39;zone&#39;: 5, &#39;weight&#39;: 1952.0, &#39;ip&#39;: &#39;&lt;redacted&gt;.204.119&#39;, &#39;id&#39;: 5481, &#39;meta&#39;: &#39;&#39;, &#39;device&#39;: &#39;disk6&#39;, &#39;port&#39;: 6201}
Mar 14 17:28:06 &lt;redacted&gt; container-replicator ERROR Remote drive not mounted
{&#39;zone&#39;: 5, &#39;weight&#39;: 1952.0, &#39;ip&#39;: &#39;&lt;redacted&gt;.204.119&#39;, &#39;id&#39;: 5481, &#39;meta&#39;: &#39;&#39;, &#39;device&#39;: &#39;disk6&#39;, &#39;port&#39;: 6201}
Mar 14 17:28:09 &lt;redacted&gt; container-replicator ERROR Remote drive not mounted
{&#39;zone&#39;: 5, &#39;weight&#39;: 1952.0, &#39;ip&#39;: &#39;&lt;redacted&gt;.204.20&#39;, &#39;id&#39;: 2311, &#39;meta&#39;: &#39;&#39;, &#39;device&#39;: &#39;disk5&#39;, &#39;port&#39;: 6201}
Mar 14 17:28:11 &lt;redacted&gt; container-replicator ERROR Remote drive not mounted
{&#39;zone&#39;: 5, &#39;weight&#39;: 1952.0, &#39;ip&#39;: &#39;&lt;redacted&gt;.204.20&#39;, &#39;id&#39;: 2311, &#39;meta&#39;: &#39;&#39;, &#39;device&#39;: &#39;disk5&#39;, &#39;port&#39;: 6201}
Mar 14 17:28:13 &lt;redacted&gt; container-replicator ERROR Remote drive not mounted
{&#39;zone&#39;: 5, &#39;weight&#39;: 1952.0, &#39;ip&#39;: &#39;&lt;redacted&gt;.204.119&#39;, &#39;id&#39;: 5481, &#39;meta&#39;: &#39;&#39;, &#39;device&#39;: &#39;disk6&#39;, &#39;port&#39;: 6201}
Mar 14 17:28:13 &lt;redacted&gt; container-replicator ERROR Remote drive not mounted
{&#39;zone&#39;: 5, &#39;weight&#39;: 1952.0, &#39;ip&#39;: &#39;&lt;redacted&gt;.204.119&#39;, &#39;id&#39;: 5481, &#39;meta&#39;: &#39;&#39;, &#39;device&#39;: &#39;disk6&#39;, &#39;port&#39;: 6201}
Mar 14 17:28:15 &lt;redacted&gt; container-replicator ERROR Remote drive not mounted
{&#39;zone&#39;: 5, &#39;weight&#39;: 1952.0, &#39;ip&#39;: &#39;&lt;redacted&gt;.204.20&#39;, &#39;id&#39;: 2311, &#39;meta&#39;: &#39;&#39;, &#39;device&#39;: &#39;disk5&#39;, &#39;port&#39;: 6201}
Mar 14 17:28:15 &lt;redacted&gt; container-replicator ERROR Remote drive not mounted
{&#39;zone&#39;: 5, &#39;weight&#39;: 1952.0, &#39;ip&#39;: &#39;&lt;redacted&gt;.204.20&#39;, &#39;id&#39;: 2311, &#39;meta&#39;: &#39;&#39;, &#39;device&#39;: &#39;disk5&#39;, &#39;port&#39;: 6201}
Mar 14 17:28:19 &lt;redacted&gt; container-replicator ERROR Remote drive not mounted
{&#39;zone&#39;: 5, &#39;weight&#39;: 1952.0, &#39;ip&#39;: &#39;&lt;redacted&gt;.204.20&#39;, &#39;id&#39;: 2311, &#39;meta&#39;: &#39;&#39;, &#39;device&#39;: &#39;disk5&#39;, &#39;port&#39;: 6201}
Mar 14 17:28:19 &lt;redacted&gt; container-replicator ERROR Remote drive not mounted
{&#39;zone&#39;: 5, &#39;weight&#39;: 1952.0, &#39;ip&#39;: &#39;&lt;redacted&gt;.204.20&#39;, &#39;id&#39;: 2311, &#39;meta&#39;: &#39;&#39;, &#39;device&#39;: &#39;disk5&#39;, &#39;port&#39;: 6201}
Mar 14 17:28:20 &lt;redacted&gt; container-replicator ERROR Remote drive not mounted
{&#39;zone&#39;: 5, &#39;weight&#39;: 1952.0, &#39;ip&#39;: &#39;&lt;redacted&gt;.204.119&#39;, &#39;id&#39;: 5481, &#39;meta&#39;: &#39;&#39;, &#39;device&#39;: &#39;disk6&#39;, &#39;port&#39;: 6201}
Mar 14 17:28:21 &lt;redacted&gt; container-replicator ERROR Remote drive not mounted
{&#39;zone&#39;: 5, &#39;weight&#39;: 1952.0, &#39;ip&#39;: &#39;&lt;redacted&gt;.204.20&#39;, &#39;id&#39;: 2311, &#39;meta&#39;: &#39;&#39;, &#39;device&#39;: &#39;disk5&#39;, &#39;port&#39;: 6201}
Mar 14 17:28:21 &lt;redacted&gt; container-replicator ERROR Remote drive not mounted
{&#39;zone&#39;: 5, &#39;weight&#39;: 1952.0, &#39;ip&#39;: &#39;&lt;redacted&gt;.204.20&#39;, &#39;id&#39;: 2311, &#39;meta&#39;: &#39;&#39;, &#39;device&#39;: &#39;disk5&#39;, &#39;port&#39;: 6201}
Mar 14 17:28:22 &lt;redacted&gt; container-replicator ERROR Remote drive not mounted
{&#39;zone&#39;: 5, &#39;weight&#39;: 1952.0, &#39;ip&#39;: &#39;&lt;redacted&gt;.204.20&#39;, &#39;id&#39;: 2311, &#39;meta&#39;: &#39;&#39;, &#39;device&#39;: &#39;disk5&#39;, &#39;port&#39;: 6201}
</pre></div>
</div>
<p>That is why this node has a lot of async pendings: a bunch of disks that
are not mounted on &lt;redacted&gt; and &lt;redacted&gt;. There may be other issues,
but clearing this up will likely drop the async pendings a fair bit, as
other nodes will be having the same problem.</p>
</div>
<div class="section" id="assessing-the-availability-risk-when-multiple-storage-servers-are-down">
<h2>Assessing the availability risk when multiple storage servers are down<a class="headerlink" href="#assessing-the-availability-risk-when-multiple-storage-servers-are-down" title="Permalink to this headline">¶</a></h2>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p class="last">This procedure will tell you if you have a problem, however, in practice
you will find that you will not use this procedure frequently.</p>
</div>
<p>If three storage nodes (or, more precisely, three disks on three
different storage nodes) are down, there is a small but nonzero
probability that user objects, containers, or accounts will not be
available.</p>
<div class="section" id="procedure">
<h3>Procedure<a class="headerlink" href="#procedure" title="Permalink to this headline">¶</a></h3>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p class="last">swift has three rings: one each for objects, containers and accounts.
This procedure should be run three times, each time specifying the
appropriate <code class="docutils literal"><span class="pre">*.builder</span></code> file.</p>
</div>
<ol class="arabic">
<li><p class="first">Determine whether all three nodes are in different Swift zones by
running the ring builder on a proxy node to determine which zones
the storage nodes are in. For example:</p>
<div class="code highlight-python"><div class="highlight"><pre><span></span>% sudo swift-ring-builder /etc/swift/object.builder
/etc/swift/object.builder, build version 1467
2097152 partitions, 3 replicas, 5 zones, 1320 devices, 0.02 balance
The minimum number of hours before a partition can be reassigned is 24
Devices:    id  zone     ip address    port     name  weight  partitions balance meta
             0     1     &lt;redacted&gt;.4  6200     disk0 1708.00       4259   -0.00
             1     1     &lt;redacted&gt;.4  6200     disk1 1708.00       4260    0.02
             2     1     &lt;redacted&gt;.4  6200     disk2 1952.00       4868    0.01
             3     1     &lt;redacted&gt;.4  6200     disk3 1952.00       4868    0.01
             4     1     &lt;redacted&gt;.4  6200     disk4 1952.00       4867   -0.01
</pre></div>
</div>
</li>
<li><p class="first">Here, node &lt;redacted&gt;.4 is in zone 1. If two or more of the three
nodes under consideration are in the same Swift zone, they do not
have any ring partitions in common; there is little/no data
availability risk if all three nodes are down.</p>
</li>
<li><p class="first">If the nodes are in three distinct Swift zones it is necessary to
whether the nodes have ring partitions in common. Run <code class="docutils literal"><span class="pre">swift-ring</span></code>
builder again, this time with the <code class="docutils literal"><span class="pre">list_parts</span></code> option and specify
the nodes under consideration. For example:</p>
<div class="code highlight-python"><div class="highlight"><pre><span></span>% sudo swift-ring-builder /etc/swift/object.builder list_parts &lt;redacted&gt;.8 &lt;redacted&gt;.15 &lt;redacted&gt;.72.2
Partition   Matches
91           2
729          2
3754         2
3769         2
3947         2
5818         2
7918         2
8733         2
9509         2
10233        2
</pre></div>
</div>
</li>
<li><p class="first">The <code class="docutils literal"><span class="pre">list_parts</span></code> option to the ring builder indicates how many ring
partitions the nodes have in common. If, as in this case,  the
first entry in the list has a ‘Matches’ column of 2 or less,  there
is no data availability risk if all three nodes are down.</p>
</li>
<li><p class="first">If the ‘Matches’ column has entries equal to 3, there is some data
availability risk if all three nodes are down. The risk is generally
small, and is proportional to the number of entries that have a 3 in
the Matches column. For example:</p>
<div class="code highlight-python"><div class="highlight"><pre><span></span>Partition   Matches
26865          3
362367         3
745940         3
778715         3
797559         3
820295         3
822118         3
839603         3
852332         3
855965         3
858016         3
</pre></div>
</div>
</li>
<li><p class="first">A quick way to count the number of rows with 3 matches is:</p>
<div class="code highlight-python"><div class="highlight"><pre><span></span>% sudo swift-ring-builder /etc/swift/object.builder list_parts &lt;redacted&gt;.8 &lt;redacted&gt;.15 &lt;redacted&gt;.72.2 | grep &quot;3$&quot; | wc -l

30
</pre></div>
</div>
</li>
<li><p class="first">In this case the nodes have 30 out of a total of 2097152 partitions
in common; about 0.001%. In this case the risk is small/nonzero.
Recall that a partition is simply a portion of the ring mapping
space, not actual data. So having partitions in common is a necessary
but not sufficient condition for data unavailability.</p>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p>We should not bring down a node for repair if it shows
Matches entries of 3 with other nodes that are also down.</p>
<p class="last">If three nodes that have 3 partitions in common are all down, there is
a nonzero probability that data are unavailable and we should work to
bring some or all of the nodes up ASAP.</p>
</div>
</li>
</ol>
</div>
</div>
<div class="section" id="swift-startup-shutdown">
<h2>Swift startup/shutdown<a class="headerlink" href="#swift-startup-shutdown" title="Permalink to this headline">¶</a></h2>
<ul class="simple">
<li>Use reload - not stop/start/restart.</li>
<li>Try to roll sets of servers (especially proxy) in groups of less
than 20% of your servers.</li>
</ul>
</div>
</div>


          </div>
        </div>
      </div>
<div class="sphinxsidebar">
    <div class="sphinxsidebarwrapper">
            <h3><a href="../index.html">Table Of Contents</a></h3>
            <ul>
<li><a class="reference internal" href="#">Server maintenance</a><ul>
<li><a class="reference internal" href="#general-assumptions">General assumptions</a></li>
<li><a class="reference internal" href="#assessing-the-health-of-swift">Assessing the health of swift</a></li>
<li><a class="reference internal" href="#recon-examples">Recon examples</a></li>
<li><a class="reference internal" href="#assessing-the-availability-risk-when-multiple-storage-servers-are-down">Assessing the availability risk when multiple storage servers are down</a><ul>
<li><a class="reference internal" href="#procedure">Procedure</a></li>
</ul>
</li>
<li><a class="reference internal" href="#swift-startup-shutdown">Swift startup/shutdown</a></li>
</ul>
</li>
</ul>

            <h4>Previous topic</h4>
            <p class="topless"><a href="procedures.html"
                                  title="previous chapter">Software configuration procedures</a></p>
            <h4>Next topic</h4>
            <p class="topless"><a href="troubleshooting.html"
                                  title="next chapter">Troubleshooting tips</a></p>
            <h3>Project Source</h3>
            <ul class="this-page-menu">
              <li><a href="http://git.openstack.org/cgit/openstack/swift
"
                     rel="nofollow">Project Source</a></li>
            </ul>
            <h3>This Page</h3>
            <ul class="this-page-menu">
              <li><a href="../_sources/ops_runbook/maintenance.txt"
                     rel="nofollow">Show Source</a></li>
            </ul>
          <div id="searchbox" style="display: none">
            <h3>Quick search</h3>
              <form class="search" action="../search.html" method="get">
                <input type="text" name="q" size="18" />
                <input type="submit" value="Go" />
                <input type="hidden" name="check_keywords" value="yes" />
                <input type="hidden" name="area" value="default" />
              </form>
              <p class="searchtip" style="font-size: 90%">
              Enter search terms or a module, class or function name.
              </p>
          </div>
          <script type="text/javascript">$('#searchbox').show(0);</script>
    </div>
</div>

      <div class="clearer"></div>
    </div>
    <div class="related" role="navigation" aria-label="related navigation">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="../genindex.html" title="General Index"
             accesskey="I">index</a></li>
        <li class="right" >
          <a href="../py-modindex.html" title="Python Module Index"
             >modules</a> |</li>
        <li class="right" >
          <a href="troubleshooting.html" title="Troubleshooting tips"
             accesskey="N">next</a> |</li>
        <li class="right" >
          <a href="procedures.html" title="Software configuration procedures"
             accesskey="P">previous</a> |</li>
        <li class="nav-item nav-item-0"><a href="../index.html">swift 2.12.1.dev102 documentation</a> &raquo;</li>
          <li class="nav-item nav-item-1"><a href="index.html" accesskey="U">Swift Ops Runbook</a> &raquo;</li> 
      </ul>
    </div>

    <div class="footer" role="contentinfo">
        &copy; Copyright 2017, OpenStack Foundation.
      Last updated on &#39;Tue Feb 14 07:57:22 2017, commit 7cb6882&#39;.
      Created using <a href="http://sphinx-doc.org/">Sphinx</a> 1.3.6.
    </div>
<script type="text/javascript">
var gaJsHost = (("https:" == document.location.protocol) ? "https://ssl." : "http://www.");
document.write(unescape("%3Cscript src='" + gaJsHost + "google-analytics.com/ga.js' type='text/javascript'%3E%3C/script%3E"));
</script>
<script type="text/javascript">
try {
//Tracking docs.openstack.org/developer/<projectname> only
//The URL is built from the project variable in conf.py
var pageTracker = _gat._getTracker("UA-17511903-1");
pageTracker._setCookiePath("/developer/swift");
pageTracker._trackPageview();
} catch(err) {}</script>

  </body>
</html>