<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN"
  "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">


<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    
    <title>Deployment &mdash; congress 5.0.0.0rc2.dev7 documentation</title>
    
    <link rel="stylesheet" href="_static/nature.css" type="text/css" />
    <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
    <link rel="stylesheet" href="_static/tweaks.css" type="text/css" />
    
    <script type="text/javascript">
      var DOCUMENTATION_OPTIONS = {
        URL_ROOT:    './',
        VERSION:     '5.0.0.0rc2.dev7',
        COLLAPSE_INDEX: false,
        FILE_SUFFIX: '.html',
        HAS_SOURCE:  true
      };
    </script>
    <script type="text/javascript" src="_static/jquery.js"></script>
    <script type="text/javascript" src="_static/underscore.js"></script>
    <script type="text/javascript" src="_static/doctools.js"></script>
    <link rel="top" title="congress 5.0.0.0rc2.dev7 documentation" href="index.html" />
    <link rel="next" title="Release Notes" href="release.html" />
    <link rel="prev" title="Troubleshooting" href="troubleshooting.html" /> 
  </head>
  <body role="document">
  <div id="header">
    <h1 id="logo"><a href="http://www.openstack.org/">OpenStack</a></h1>
    <ul id="navigation">
      
      <li><a href="http://www.openstack.org/" title="Go to the Home page" class="link">Home</a></li>
      <li><a href="http://www.openstack.org/projects/" title="Go to the OpenStack Projects page">Projects</a></li>
      <li><a href="http://www.openstack.org/user-stories/" title="Go to the User Stories page" class="link">User Stories</a></li>
      <li><a href="http://www.openstack.org/community/" title="Go to the Community page" class="link">Community</a></li>
      <li><a href="http://www.openstack.org/blog/" title="Go to the OpenStack Blog">Blog</a></li>
      <li><a href="http://wiki.openstack.org/" title="Go to the OpenStack Wiki">Wiki</a></li>
      <li><a href="http://docs.openstack.org/" title="Go to OpenStack Documentation" class="current">Documentation</a></li>
      
    </ul>
  </div>
  

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          <div class="body" role="main">
            
  <div class="section" id="deployment">
<span id="id1"></span><h1>Deployment<a class="headerlink" href="#deployment" title="Permalink to this headline">¶</a></h1>
<p>Congress has two modes for deployment: single-process and multi-process.
If you are interested in test-driving Congress or are not concerned
about high-availability, the single-process deployment is best because it
is easiest to set up.  If you are interested in making Congress highly-available
you want the multi-process deployment.</p>
<p>In the single-process version, you run Congress as a single operating-system
process on one node (i.e. container, VM, physical machine).</p>
<p>In the multi-process version, you start with the 3 components of Congress
(the API, the policy engine, and the datasource drivers).  You choose how many
copies of each component you want to run, how you want to distribute those
components across processes, and how you want to distribute those processes
across nodes.</p>
<p>Section <a class="reference internal" href="#config"><span>Configuration Options</span></a> describes the common configuration options for both
single-process and multi-process deployments.  After that <a class="reference internal" href="ha-overview.html#ha-overview"><span>HA Overview</span></a>
and <a class="reference internal" href="ha-deployment.html#ha-deployment"><span>HA Deployment</span></a> describe how to set up the multi-process deployment.</p>
<div class="section" id="configuration-options">
<span id="config"></span><h2>Configuration Options<a class="headerlink" href="#configuration-options" title="Permalink to this headline">¶</a></h2>
<p>In this section we highlight the configuration options that are specific
to Congress.  To generate a sample configuration file that lists all
available options, along with descriptions, run the following commands:</p>
<div class="highlight-python"><div class="highlight"><pre><span></span>$ cd /path/to/congress
$ tox -egenconfig
</pre></div>
</div>
<p>The tox command will create the file <code class="docutils literal"><span class="pre">etc/congress.conf.sample</span></code>, which has
a comprehensive list of options.  All options have default values, which
means that even if you specify no options Congress will run.</p>
<p>The options most important to Congress are described below, all of which
appear under the [DEFAULT] section of the configuration file.</p>
<dl class="docutils">
<dt><code class="docutils literal"><span class="pre">drivers</span></code></dt>
<dd>The list of permitted datasource drivers.  Default is the empty list.
The list is a comma separated list of Python class paths. For example:
drivers = congress.datasources.neutronv2_driver.NeutronV2Driver,congress.datasources.glancev2_driver.GlanceV2Driver</dd>
<dt><code class="docutils literal"><span class="pre">datasource_sync_period</span></code></dt>
<dd>The number of seconds to wait between synchronizing datasource config
from the database.  Default is 0.</dd>
<dt><code class="docutils literal"><span class="pre">enable_execute_action</span></code></dt>
<dd>Whether or not congress will execute actions.  If false, Congress will
never execute any actions to do manual reactive enforcement, even if there
are policy statements that say actions should be executed and the
conditions of those actions become true.  Default is True.</dd>
</dl>
<p>One of Congress&#8217;s new experimental features is distributing its services
across multiple services and even hosts.  Here are the options for using
that feature.</p>
<dl class="docutils">
<dt><code class="docutils literal"><span class="pre">bus_id</span></code></dt>
<dd>Unique ID of DSE bus.  Can be any string. Defaults to &#8216;bus&#8217;.
ID should be same across all the processes of a single congress instance
and should be unique across different congress instances.
Used if you want to create multiple, distributed instances of Congress and
can be ignored if only one congress instance is deployed as single process
in rabbitMQ cluster. Appears in the [dse] section.</dd>
</dl>
<p>Here are the most often-used, but standard OpenStack options.  These
are specified in the [DEFAULT] section of the configuration file.</p>
<dl class="docutils">
<dt><code class="docutils literal"><span class="pre">auth_strategy</span></code></dt>
<dd>Method for authenticating Congress users.
Can be assigned to either &#8216;keystone&#8217; meaning that the user must provide
Keystone credentials or to &#8216;noauth&#8217; meaning that no authentication is
required.  Default is &#8216;keystone&#8217;.</dd>
<dt><code class="docutils literal"><span class="pre">verbose</span></code></dt>
<dd>Controls whether the INFO-level of logging is enabled.  If false, logging
level will be set to WARNING.  Default is true.  Deprecated.</dd>
<dt><code class="docutils literal"><span class="pre">debug</span></code></dt>
<dd>Whether or not the DEBUG-level of logging is enabled. Default is false.</dd>
<dt><code class="docutils literal"><span class="pre">transport_url</span></code></dt>
<dd>URL to the shared messaging service. It is not needed in a single-process
Congress deployment, but must be specified in a multi-process Congress
deployment.</dd>
</dl>
<div class="highlight-text"><div class="highlight"><pre><span></span>[DEFAULT]
transport_url = rabbit://&lt;rabbit-userid&gt;:&lt;rabbit-password&gt;@&lt;rabbit-host-address&gt;:&lt;port&gt;
</pre></div>
</div>
</div>
<div class="section" id="ha-overview">
<span id="id2"></span><h2>HA Overview<a class="headerlink" href="#ha-overview" title="Permalink to this headline">¶</a></h2>
<p>Some applications require Congress to be highly available. Some
applications require a Congress Policy Engine (PE) to handle a high volume of
queries. This guide describes Congress support for High Availability (HA)
High Throughput (HT) deployment.</p>
<p>Please see the <a class="reference external" href="http://docs.openstack.org/ha-guide/index.html">OpenStack High Availability Guide</a> for details on how to
install and configure OpenStack for High Availability.</p>
<div class="section" id="ha-types">
<h3>HA Types<a class="headerlink" href="#ha-types" title="Permalink to this headline">¶</a></h3>
<div class="section" id="warm-standby">
<h4>Warm Standby<a class="headerlink" href="#warm-standby" title="Permalink to this headline">¶</a></h4>
<p>Warm Standby is when a software component is installed and available on the
secondary node. The secondary node is up and running. In the case of a
failure on the primary node, the software component is started on the
secondary node. This process is usually automated using a cluster manager.
Data is regularly mirrored to the secondary system using disk based replication
or shared disk. This generally provides a recovery time of a few minutes.</p>
</div>
<div class="section" id="active-active-load-balanced">
<h4>Active-Active (Load-Balanced)<a class="headerlink" href="#active-active-load-balanced" title="Permalink to this headline">¶</a></h4>
<p>In this method, both the primary and secondary systems are active and
processing requests in parallel. Data replication happens through software
capabilities and would be bi-directional. This generally provides a recovery
time that is instantaneous.</p>
</div>
</div>
<div class="section" id="congress-haht">
<h3>Congress HAHT<a class="headerlink" href="#congress-haht" title="Permalink to this headline">¶</a></h3>
<p>Congress provides Active-Active for the Policy Engine and Warm Standby for
the Datasource Drivers.</p>
<p>Run N instances of the Congress Policy Engine in active-active
configuration, so both the primary and secondary systems are active
and processing requests in parallel.</p>
<p>One Datasource Driver (DSD) per physical datasource, publishing data on
oslo-messaging to all policy engines.</p>
<div class="highlight-text"><div class="highlight"><pre><span></span>+-------------------------------------+      +--------------+
|       Load Balancer (eg. HAProxy)   | &lt;----+ Push client  |
+----+-------------+-------------+----+      +--------------+
     |             |             |
PE   |        PE   |        PE   |        all+DSDs node
+---------+   +---------+   +---------+   +-----------------+
| +-----+ |   | +-----+ |   | +-----+ |   | +-----+ +-----+ |
| | API | |   | | API | |   | | API | |   | | DSD | | DSD | |
| +-----+ |   | +-----+ |   | +-----+ |   | +-----+ +-----+ |
| +-----+ |   | +-----+ |   | +-----+ |   | +-----+ +-----+ |
| | PE  | |   | | PE  | |   | | PE  | |   | | DSD | | DSD | |
| +-----+ |   | +-----+ |   | +-----+ |   | +-----+ +-----+ |
+---------+   +---------+   +---------+   +--------+--------+
     |             |             |                 |
     |             |             |                 |
     +--+----------+-------------+--------+--------+
        |                                 |
        |                                 |
+-------+----+   +------------------------+-----------------+
|  Oslo Msg  |   | DBs (policy, config, push data, exec log)|
+------------+   +------------------------------------------+
</pre></div>
</div>
<div class="section" id="details">
<h4>Details<a class="headerlink" href="#details" title="Permalink to this headline">¶</a></h4>
<ul class="simple">
<li>Datasource Drivers (DSDs):<ul>
<li>One datasource driver per physical datasource</li>
<li>All DSDs run in a single DSE node (process)</li>
<li>Push DSDs: optionally persist data in push data DB, so a new snapshot
can be obtained whenever needed</li>
<li>Warm Standby:<ul>
<li>Only one set of DSDs running at a given time; backup instances ready
to launch</li>
<li>For pull DSDs, warm standby is most appropriate because warm startup
time is low (seconds) relative to frequency of data pulls</li>
<li>For push DSDs, warm standby is generally sufficient except for use cases
that demand sub-second latency even during a failover</li>
</ul>
</li>
</ul>
</li>
<li>Policy Engine (PE):<ul>
<li>Replicate policy engine in active-active configuration.</li>
<li>Policy synchronized across PE instances via Policy DB</li>
<li>Every instance subscribes to the same data on oslo-messaging</li>
<li>Reactive Enforcement:
All PE instances initiate reactive policy actions, but each DSD locally
selects a leader to listen to. The DSD ignores execution requests
initiated by all other PE instances.<ul>
<li>Every PE instance computes the required reactive enforcement actions and
initiates the corresponding execution requests over oslo-messaging</li>
<li>Each DSD locally picks a PE instance as leader (say the first instance
the DSD hears from in the asymmetric node deployment, or the PE
instance on the same node as the DSD in a symmetric node deployment) and
executes only requests from that PE</li>
<li>If heartbeat contact is lost with the leader, the DSD selects a new
leader</li>
<li>Each PE instance is unaware of whether it is a leader</li>
</ul>
</li>
<li>Node Configurations:<ul>
<li>Congress supports the Two Node-Types (API+PE nodes, all-DSDs) node
configuration because it gives reasonable support for high-load DSDs
while keeping the deployment complexities low.</li>
</ul>
</li>
<li>Local Leader for Action Execution:<ul>
<li>Local Leader: every PE instance sends action-execution requests, but
each receiving DSD locally picks a &#8220;leader&#8221; to listen to</li>
<li>Because there is a single active DSD for a given data source,
it is a natural spot to locally choose a &#8220;leader&#8221; among the PE instances
sending reactive enforcement action execution requests. Congress
supports the local leader style because it avoids the deployment
complexities associated with global leader election. Furthermore,
because all PE instances perform reactive enforcement and send action
execution requests, the redundancy opens up the possibility for zero
disruption to reactive enforcement when a PE instance fails.</li>
</ul>
</li>
</ul>
</li>
<li>API:<ul>
<li>Each node has an active API service</li>
<li>Each API service routes requests for the PE to its associated intranode PE</li>
<li>Requests for any other service (eg. get data source status) are routed to
the Datasource and/or Policy Engine, which will be fielded by some active
instance of the service on some node</li>
</ul>
</li>
<li>Load balancer:<ul>
<li>Layer 7 load balancer (e.g. HAProxy) distributes incoming API calls among
the nodes (each running an API service).</li>
<li>load balancer optionally configured to use sticky session to pin each API
caller to a particular node. This configuration avoids the experience of
going back in time.</li>
</ul>
</li>
<li>External components (load balancer, DBs, and oslo messaging bus) can be made
highly available using standard solutions (e.g. clustered LB, HA rabbitMQ)</li>
</ul>
</div>
</div>
<div class="section" id="performance-impact">
<h3>Performance Impact<a class="headerlink" href="#performance-impact" title="Permalink to this headline">¶</a></h3>
<ul class="simple">
<li>Increased latency due to network communication required by multi-node
deployment</li>
<li>Increased reactive enforcement latency if action executions are persistently
logged to facilitate smoother failover</li>
<li>PE replication can achieve greater query throughput</li>
</ul>
</div>
<div class="section" id="cautions-and-limitations">
<h3>Cautions and Limitations<a class="headerlink" href="#cautions-and-limitations" title="Permalink to this headline">¶</a></h3>
<ul class="simple">
<li>Replicated PE deployment is new in the Newton release and a major departure
from the previous model. As a result, the deployer may be more likely to
experience unexpected issues.</li>
<li>In the Newton release, creating a new policy requires locking a database
table. As a result, it should not be deployed with a database backend that
does not support table locking (e.g., Galera). The limitation is expected to
be removed in the Ocata release.</li>
<li>Different PE instances may be out-of-sync in their data and policies
(eventual consistency).
The issue is generally made transparent to the end  user by
configuring the load balancer to make each user sticky to a particular PE
instance. But if a user reaches a different PE instance (say because of load
balancer configuration or because the original instance went down), the end
user reaches a different instance and may experience out-of-sync artifacts.</li>
</ul>
</div>
</div>
<div class="section" id="ha-deployment">
<span id="id4"></span><h2>HA Deployment<a class="headerlink" href="#ha-deployment" title="Permalink to this headline">¶</a></h2>
<div class="section" id="overview">
<h3>Overview<a class="headerlink" href="#overview" title="Permalink to this headline">¶</a></h3>
<p>This section shows how to deploy Congress with High Availability (HA). For an
architectural overview, please see the <a class="reference internal" href="ha-overview.html#ha-overview"><span>HA Overview</span></a>.</p>
<p>An HA deployment of Congress involves five main steps.</p>
<ol class="arabic simple">
<li>Deploy messaging and database infrastructure to be shared by all the
Congress nodes.</li>
<li>Prepare the hosts to run Congress nodes.</li>
<li>Deploy N (at least 2) policy-engine nodes.</li>
<li>Deploy one datasource-drivers node.</li>
<li>Deploy a load-balancer to load-balance between the N policy-engine nodes.</li>
</ol>
<p>The following sections describe each step in more detail.</p>
</div>
<div class="section" id="shared-services">
<h3>Shared Services<a class="headerlink" href="#shared-services" title="Permalink to this headline">¶</a></h3>
<p>All the Congress nodes share a database backend. To setup a database backend
for Congress, please follow the database portion of
<a class="reference external" href="http://docs.openstack.org/developer/congress/README.html?highlight=readme#separate-install">separate install instructions</a>.</p>
<p>Various solutions exist to avoid creating a single point of failure with the
database backend.</p>
<p>Note: If a replicated database solution is used, it must support table
locking. Galera, for example, would not work. This limitation is expected to
be removed in the Ocata release.</p>
<p>A shared messaging service is also required. Refer to <a class="reference external" href="http://docs.openstack.org/ha-guide/shared-messaging.html">Shared Messaging</a> for
instructions for installing and configuring RabbitMQ.</p>
</div>
<div class="section" id="hosts-preparation">
<h3>Hosts Preparation<a class="headerlink" href="#hosts-preparation" title="Permalink to this headline">¶</a></h3>
<p>Congress should be installed on each host expected to run a Congress node.
Please follow the directions in <a class="reference external" href="http://docs.openstack.org/developer/congress/README.html?highlight=readme#separate-install">separate install instructions</a> to install
Congress on each host, skipping the local database portion.</p>
<p>In the configuration file, a <code class="docutils literal"><span class="pre">transport_url</span></code> should be specified to use the
RabbitMQ messaging service configured in step 1.</p>
<p>For example:</p>
<div class="highlight-text"><div class="highlight"><pre><span></span>[DEFAULT]
transport_url = rabbit://&lt;rabbit-userid&gt;:&lt;rabbit-password&gt;@&lt;rabbit-host-address&gt;:5672
</pre></div>
</div>
<p>In addition, the <code class="docutils literal"><span class="pre">replicated_policy_engine</span></code> option should be set to <code class="docutils literal"><span class="pre">True</span></code>.</p>
<div class="highlight-text"><div class="highlight"><pre><span></span>[DEFAULT]
replicated_policy_engine = True
</pre></div>
</div>
<p>All hosts should be configured with a database connection that points to the
shared database deployed in step 1, not the local address shown in
<a class="reference external" href="http://docs.openstack.org/developer/congress/README.html?highlight=readme#separate-install">separate install instructions</a>.</p>
<p>For example:</p>
<div class="highlight-text"><div class="highlight"><pre><span></span>[database]
connection = mysql+pymysql://root:&lt;database-password&gt;@&lt;shared-database-ip-address&gt;/congress?charset=utf8
</pre></div>
</div>
</div>
<div class="section" id="datasource-drivers-node">
<h3>Datasource Drivers Node<a class="headerlink" href="#datasource-drivers-node" title="Permalink to this headline">¶</a></h3>
<p>In this step, we deploy a single datasource-drivers node in warm-standby style.</p>
<p>The datasource-drivers node can be started directly with the following command:</p>
<blockquote>
<div><div class="highlight-console"><div class="highlight"><pre><span></span><span class="gp">$</span> python /usr/local/bin/congress-server --datasources --node-id<span class="o">=</span>&lt;unique_node_id&gt;
</pre></div>
</div>
</div></blockquote>
<p>A unique node-id (distinct from all the policy-engine nodes) must be specified.</p>
<p>For warm-standby deployment, an external manager is used to launch and manage
the datasource-drivers node. In this document, we sketch how to deploy the
datasource-drivers node with <a class="reference external" href="http://clusterlabs.org/">Pacemaker</a> .</p>
<p>See the <a class="reference external" href="http://docs.openstack.org/ha-guide/index.html">OpenStack High Availability Guide</a> for general usage of Pacemaker
and how to deploy Pacemaker cluster stack. The guide also has some HA
configuration guidance for other OpenStack projects.</p>
<div class="section" id="prepare-ocf-resource-agent">
<h4>Prepare OCF resource agent<a class="headerlink" href="#prepare-ocf-resource-agent" title="Permalink to this headline">¶</a></h4>
<p>You need a custom Resource Agent (RA) for DataSoure Node HA. The custom RA is
located in Congress repository, <code class="docutils literal"><span class="pre">/path/to/congress/script/ocf/congress-datasource</span></code>.
Install the RA with following steps.</p>
<div class="highlight-sh"><div class="highlight"><pre><span></span>$ <span class="nb">cd</span> /usr/lib/ocf/resource.d
$ mkdir openstack
$ <span class="nb">cd</span> openstack
$ cp /path/to/congress/script/ocf/congress-datasource ./congress-datasource
$ chmod a+rx congress-datasource
</pre></div>
</div>
</div>
<div class="section" id="configuring-the-resource-agent">
<h4>Configuring the Resource Agent<a class="headerlink" href="#configuring-the-resource-agent" title="Permalink to this headline">¶</a></h4>
<p>You can now add the Pacemaker configuration for Congress DataSource Node resource.
Connect to the Pacemaker cluster with the <em>crm configure</em> command and add the
following cluster resources. After adding the resource make sure <em>commit</em>
the change.</p>
<div class="highlight-sh"><div class="highlight"><pre><span></span>primitive ds-node ocf:openstack:congress-datasource <span class="se">\</span>
   params <span class="nv">config</span><span class="o">=</span><span class="s2">&quot;/etc/congress/congress.conf&quot;</span> <span class="se">\</span>
   <span class="nv">node_id</span><span class="o">=</span><span class="s2">&quot;datasource-node&quot;</span> <span class="se">\</span>
   op monitor <span class="nv">interval</span><span class="o">=</span><span class="s2">&quot;30s&quot;</span> <span class="nv">timeout</span><span class="o">=</span><span class="s2">&quot;30s&quot;</span>
</pre></div>
</div>
<p>Make sure that all nodes in the cluster have same config file with same name and
path since DataSource Node resource, <code class="docutils literal"><span class="pre">ds-node</span></code>, uses config file defined at
<em>config</em> parameter to launch the resource.</p>
<p>The RA has following configurable parameters.</p>
<ul class="simple">
<li>config: a path of Congress&#8217;s config file</li>
<li>node_id(Option): a node id of the datasource node. Default is &#8220;datasource-node&#8221;.</li>
<li>binary(Option): a path of Congress binary Default is &#8220;/usr/local/bin/congress-server&#8221;.</li>
<li>additional_parameters(Option): additional parameters of congress-server</li>
</ul>
</div>
</div>
<div class="section" id="policy-engine-nodes">
<h3>Policy Engine Nodes<a class="headerlink" href="#policy-engine-nodes" title="Permalink to this headline">¶</a></h3>
<p>In this step, we deploy N (at least 2) policy-engine nodes, each with an
associated API server. This step should be done only after the
<a class="reference internal" href="#datasource-drivers-node">Datasource Drivers Node</a> is deployed. Each node can be started as follows:</p>
<blockquote>
<div><div class="highlight-console"><div class="highlight"><pre><span></span><span class="gp">$</span> python /usr/local/bin/congress-server --api --policy-engine --node-id<span class="o">=</span>&lt;unique_node_id&gt;
</pre></div>
</div>
</div></blockquote>
<p>Each node must have a unique node-id specified as a commandline option.</p>
<p>For high availability, each node is usually deployed on a different host. If
multiple nodes are to be deployed on the same host, each node must have a
different port specified using the <code class="docutils literal"><span class="pre">bind_port</span></code> configuration option in the
congress configuration file.</p>
</div>
<div class="section" id="load-balancer">
<h3>Load-balancer<a class="headerlink" href="#load-balancer" title="Permalink to this headline">¶</a></h3>
<p>A load-balancer should be used to distribute incoming API requests to the N
policy-engine (and API service) nodes deployed in step 3.
It is recommended that a sticky configuration be used to avoid exposing a user
to out-of-sync artifacts when the user hits different policy-engine nodes.</p>
<p><a class="reference external" href="http://www.haproxy.org/">HAProxy</a> is a popular load-balancer for this
purpose. The HAProxy section of the <a class="reference external" href="http://docs.openstack.org/ha-guide/index.html">OpenStack High Availability Guide</a>
has instructions for deploying HAProxy for high availability.</p>
</div>
</div>
</div>


          </div>
        </div>
      </div>
<div class="sphinxsidebar">
    <div class="sphinxsidebarwrapper">
            <h3><a href="index.html">Table Of Contents</a></h3>
            <ul>
<li><a class="reference internal" href="#">Deployment</a><ul>
<li><a class="reference internal" href="#configuration-options">Configuration Options</a></li>
<li><a class="reference internal" href="#ha-overview">HA Overview</a><ul>
<li><a class="reference internal" href="#ha-types">HA Types</a><ul>
<li><a class="reference internal" href="#warm-standby">Warm Standby</a></li>
<li><a class="reference internal" href="#active-active-load-balanced">Active-Active (Load-Balanced)</a></li>
</ul>
</li>
<li><a class="reference internal" href="#congress-haht">Congress HAHT</a><ul>
<li><a class="reference internal" href="#details">Details</a></li>
</ul>
</li>
<li><a class="reference internal" href="#performance-impact">Performance Impact</a></li>
<li><a class="reference internal" href="#cautions-and-limitations">Cautions and Limitations</a></li>
</ul>
</li>
<li><a class="reference internal" href="#ha-deployment">HA Deployment</a><ul>
<li><a class="reference internal" href="#overview">Overview</a></li>
<li><a class="reference internal" href="#shared-services">Shared Services</a></li>
<li><a class="reference internal" href="#hosts-preparation">Hosts Preparation</a></li>
<li><a class="reference internal" href="#datasource-drivers-node">Datasource Drivers Node</a><ul>
<li><a class="reference internal" href="#prepare-ocf-resource-agent">Prepare OCF resource agent</a></li>
<li><a class="reference internal" href="#configuring-the-resource-agent">Configuring the Resource Agent</a></li>
</ul>
</li>
<li><a class="reference internal" href="#policy-engine-nodes">Policy Engine Nodes</a></li>
<li><a class="reference internal" href="#load-balancer">Load-balancer</a></li>
</ul>
</li>
</ul>
</li>
</ul>

            <h4>Previous topic</h4>
            <p class="topless"><a href="troubleshooting.html"
                                  title="previous chapter">Troubleshooting</a></p>
            <h4>Next topic</h4>
            <p class="topless"><a href="release.html"
                                  title="next chapter">Release Notes</a></p>
            <h3>Project Source</h3>
            <ul class="this-page-menu">
              <li><a href="http://git.openstack.org/cgit/openstack/congress
"
                     rel="nofollow">Project Source</a></li>
            </ul>
            <h3>This Page</h3>
            <ul class="this-page-menu">
              <li><a href="_sources/deployment.txt"
                     rel="nofollow">Show Source</a></li>
            </ul>
          <div id="searchbox" style="display: none">
            <h3>Quick search</h3>
              <form class="search" action="search.html" method="get">
                <input type="text" name="q" size="18" />
                <input type="submit" value="Go" />
                <input type="hidden" name="check_keywords" value="yes" />
                <input type="hidden" name="area" value="default" />
              </form>
              <p class="searchtip" style="font-size: 90%">
              Enter search terms or a module, class or function name.
              </p>
          </div>
          <script type="text/javascript">$('#searchbox').show(0);</script>
    </div>
</div>

      <div class="clearer"></div>
    </div>
    <div class="related" role="navigation" aria-label="related navigation">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="genindex.html" title="General Index"
             accesskey="I">index</a></li>
        <li class="right" >
          <a href="py-modindex.html" title="Python Module Index"
             >modules</a> |</li>
        <li class="right" >
          <a href="release.html" title="Release Notes"
             accesskey="N">next</a> |</li>
        <li class="right" >
          <a href="troubleshooting.html" title="Troubleshooting"
             accesskey="P">previous</a> |</li>
        <li class="nav-item nav-item-0"><a href="index.html">congress 5.0.0.0rc2.dev7 documentation</a> &raquo;</li> 
      </ul>
    </div>

    <div class="footer" role="contentinfo">
        &copy; Copyright 2013, OpenStack Foundation.
      Created using <a href="http://sphinx-doc.org/">Sphinx</a> 1.3.6.
    </div>
<script type="text/javascript">
var gaJsHost = (("https:" == document.location.protocol) ? "https://ssl." : "http://www.");
document.write(unescape("%3Cscript src='" + gaJsHost + "google-analytics.com/ga.js' type='text/javascript'%3E%3C/script%3E"));
</script>
<script type="text/javascript">
try {
//Tracking docs.openstack.org/developer/<projectname> only
//The URL is built from the project variable in conf.py
var pageTracker = _gat._getTracker("UA-17511903-1");
pageTracker._setCookiePath("/developer/congress");
pageTracker._trackPageview();
} catch(err) {}</script>

  </body>
</html>