<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN"
  "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">


<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    
    <title>Team and repository tags &mdash; bifrost 3.0.1.dev1 documentation</title>
    
    <link rel="stylesheet" href="_static/nature.css" type="text/css" />
    <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
    <link rel="stylesheet" href="_static/tweaks.css" type="text/css" />
    
    <script type="text/javascript">
      var DOCUMENTATION_OPTIONS = {
        URL_ROOT:    './',
        VERSION:     '3.0.1.dev1',
        COLLAPSE_INDEX: false,
        FILE_SUFFIX: '.html',
        HAS_SOURCE:  true
      };
    </script>
    <script type="text/javascript" src="_static/jquery.js"></script>
    <script type="text/javascript" src="_static/underscore.js"></script>
    <script type="text/javascript" src="_static/doctools.js"></script>
    <link rel="top" title="bifrost 3.0.1.dev1 documentation" href="index.html" />
    <link rel="next" title="Contributing" href="contributing.html" />
    <link rel="prev" title="Welcome to bifrost’s documentation!" href="index.html" /> 
  </head>
  <body role="document">
  <div id="header">
    <h1 id="logo"><a href="http://www.openstack.org/">OpenStack</a></h1>
    <ul id="navigation">
      
      <li><a href="http://www.openstack.org/" title="Go to the Home page" class="link">Home</a></li>
      <li><a href="http://www.openstack.org/projects/" title="Go to the OpenStack Projects page">Projects</a></li>
      <li><a href="http://www.openstack.org/user-stories/" title="Go to the User Stories page" class="link">User Stories</a></li>
      <li><a href="http://www.openstack.org/community/" title="Go to the Community page" class="link">Community</a></li>
      <li><a href="http://www.openstack.org/blog/" title="Go to the OpenStack Blog">Blog</a></li>
      <li><a href="http://wiki.openstack.org/" title="Go to the OpenStack Wiki">Wiki</a></li>
      <li><a href="http://docs.openstack.org/" title="Go to OpenStack Documentation" class="current">Documentation</a></li>
      
    </ul>
  </div>
  

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          <div class="body" role="main">
            
  <div class="section" id="team-and-repository-tags">
<h1>Team and repository tags<a class="headerlink" href="#team-and-repository-tags" title="Permalink to this headline">¶</a></h1>
<a class="reference external image-reference" href="http://governance.openstack.org/reference/tags/index.html"><img src="http://governance.openstack.org/badges/bifrost.svg" /></a>
<div class="section" id="bifrost">
<h2>Bifrost<a class="headerlink" href="#bifrost" title="Permalink to this headline">¶</a></h2>
<p>Bifrost (pronounced bye-frost) is a set of Ansible playbooks that
automates the task of deploying a base image onto a set of known hardware using
ironic. It provides modular utility for one-off operating system deployment
with as few operational requirements as reasonably possible.</p>
</div>
<div class="section" id="use-cases">
<h2>Use Cases<a class="headerlink" href="#use-cases" title="Permalink to this headline">¶</a></h2>
<ul class="simple">
<li>Installation of ironic in standalone/noauth mode without other OpenStack
components.</li>
<li>Deployment of an operating system to a known pool of hardware as
a batch operation.</li>
<li>Testing and development of ironic in a standalone use case.</li>
</ul>
</div>
<div class="section" id="use">
<h2>Use<a class="headerlink" href="#use" title="Permalink to this headline">¶</a></h2>
<p>Installation and use of bifrost is split into roughly three steps:</p>
<ul class="simple">
<li><strong>install</strong>:
prepare the local environment by downloading and/or building machine images,
and installing and configuring the necessary services.</li>
<li><strong>enroll-dynamic</strong>:
take as input a customizable hardware inventory file and enroll the
listed hardware with ironic, configuring each appropriately for deployment
with the previously-downloaded images.</li>
<li><strong>deploy-dynamic</strong>:
instruct ironic to deploy the operating system onto each machine.</li>
</ul>
<p>Supported operating systems:</p>
<ul class="simple">
<li>Ubuntu 14.04, 14.10, 15.04, 16.04</li>
<li>Red Hat Enterprise Linux (RHEL) 7</li>
<li>CentOS 7</li>
<li>Fedora 22</li>
<li>openSUSE Leap 42.1, 42.2</li>
</ul>
</div>
<div class="section" id="pre-install-steps">
<h2>Pre-install steps<a class="headerlink" href="#pre-install-steps" title="Permalink to this headline">¶</a></h2>
<p>Installing bifrost on RHEL or CentOS requires a few extra pre-install steps.</p>
<div class="section" id="enable-additional-repositories-rhel-only">
<h3>Enable additional repositories (RHEL only)<a class="headerlink" href="#enable-additional-repositories-rhel-only" title="Permalink to this headline">¶</a></h3>
<p>The extras and optional yum repositories must be enabled to satisfy
bifrost&#8217;s dependencies. To check:</p>
<div class="highlight-python"><div class="highlight"><pre><span></span>sudo yum repolist | grep &#39;optional\|extras&#39;
</pre></div>
</div>
<p>To add the repositories:</p>
<div class="highlight-python"><div class="highlight"><pre><span></span>sudo yum repolist all | grep &#39;optional\|extras&#39;
</pre></div>
</div>
<p>The output will look like this:</p>
<div class="highlight-python"><div class="highlight"><pre><span></span>!rhui-REGION-rhel-server-debug-extras/7Server/x86_64        Red H disabled
rhui-REGION-rhel-server-debug-optional/7Server/x86_64       Red H disabled
rhui-REGION-rhel-server-extras/7Server/x86_64               Red H disabled
rhui-REGION-rhel-server-optional/7Server/x86_64             Red H disabled
rhui-REGION-rhel-server-source-extras/7Server/x86_64        Red H disabled
rhui-REGION-rhel-server-source-optional/7Server/x86_64      Red H disabled
</pre></div>
</div>
<p>Use the names of the repositories (minus the version and architecture) to enable them:</p>
<div class="highlight-python"><div class="highlight"><pre><span></span>sudo yum-config-manager --enable rhui-REGION-rhel-server-optional
sudo yum-config-manager --enable rhui-REGION-rhel-server-extras
</pre></div>
</div>
</div>
<div class="section" id="enable-the-epel-repository-rhel">
<h3>Enable the EPEL repository (RHEL)<a class="headerlink" href="#enable-the-epel-repository-rhel" title="Permalink to this headline">¶</a></h3>
<p>The Extra Packages for Enterprise Linux (EPEL) repository contains
some of bifrost&#8217;s dependencies. To enable it, install the
<code class="docutils literal"><span class="pre">epel-release</span></code> package as follows:</p>
<div class="highlight-python"><div class="highlight"><pre><span></span>sudo yum install https://dl.fedoraproject.org/pub/epel/epel-release-latest-7.noarch.rpm
</pre></div>
</div>
</div>
<div class="section" id="enable-the-epel-repository-centos">
<h3>Enable the EPEL repository (CentOS)<a class="headerlink" href="#enable-the-epel-repository-centos" title="Permalink to this headline">¶</a></h3>
<p>To enable EPEL on CentOS, run:</p>
<div class="highlight-python"><div class="highlight"><pre><span></span>sudo yum install epel-release
</pre></div>
</div>
</div>
</div>
<div class="section" id="installation">
<h2>Installation<a class="headerlink" href="#installation" title="Permalink to this headline">¶</a></h2>
<p>The installation is split into two parts.</p>
<p>The first part is a bash script which lays the basic groundwork of installing
Ansible itself.</p>
<p>Bifrost source code should be pulled directly from git first:</p>
<div class="highlight-python"><div class="highlight"><pre><span></span>git clone https://git.openstack.org/openstack/bifrost.git
cd bifrost
</pre></div>
</div>
<p>Edit <code class="docutils literal"><span class="pre">./playbooks/inventory/group_vars/*</span></code> to match your environment. The
target file is intended for steps executed upon the target server, such as
installation, or image generation.  The baremetal file is geared for steps
performed on baremetal nodes, such as enrollment, deployment, or any other
custom playbooks that a user may bolt on to this toolkit.</p>
<ul class="simple">
<li>If MySQL is already installed, update <code class="docutils literal"><span class="pre">mysql_password</span></code> to match
your local installation.</li>
<li>Change <code class="docutils literal"><span class="pre">network_interface</span></code> to match the interface that will need
to service DHCP requests.</li>
<li>Change the <code class="docutils literal"><span class="pre">ironic_db_password</span></code> which is set by Ansible in MySQL
and in ironic&#8217;s configuration file.</li>
</ul>
<p>The install process builds or modifies a disk image to deploy. The
following two settings (which are mutually exclusive) allow you to
choose if a partition image is used or an image is created with
diskimage-builder:</p>
<div class="highlight-python"><div class="highlight"><pre><span></span>create_image_via_dib: true
transform_boot_image: false
</pre></div>
</div>
<p>If you are running the installation behind a proxy, export the
environment variables <code class="docutils literal"><span class="pre">http_proxy</span></code> and <code class="docutils literal"><span class="pre">https_proxy</span></code> so that
Ansible will use these proxy settings.</p>
<p>The recommended path for use is with a local Ansible installation, and to
install the library requirements. Alternatively the <code class="docutils literal"><span class="pre">env-setup.sh</span></code> script
will install ansible and all of bifrost&#8217;s dependencies.</p>
<p>If you use <code class="docutils literal"><span class="pre">env-setup.sh</span></code>, ansible will be installed along
with its missing Python dependencies into user&#8217;s <code class="docutils literal"><span class="pre">~/.local</span></code> directory.</p>
<p>Warning:</p>
<div class="highlight-python"><div class="highlight"><pre><span></span>Use of the ``env-setup.sh`` script can squash an existing
Ansible installation, and is intended primarily for development
and testing.
</pre></div>
</div>
<p>Note:</p>
<div class="highlight-python"><div class="highlight"><pre><span></span>The next setup steps require elevated privilges, and might need to
be executed with the ``sudo`` command, depending on the access rights
of the user executing the command.
</pre></div>
</div>
<p>If using the environment setup script:</p>
<div class="highlight-python"><div class="highlight"><pre><span></span>bash ./scripts/env-setup.sh
export PATH=${HOME}/.local/bin:${PATH}
cd playbooks
</pre></div>
</div>
<p>Otherwise:</p>
<div class="highlight-python"><div class="highlight"><pre><span></span>pip install -r requirements.txt
cd playbooks
</pre></div>
</div>
<p>The second part is an Ansible playbook that installs and configures ironic
in a stand-alone fashion.</p>
<ul class="simple">
<li>Keystone is NOT installed by default, and ironic&#8217;s API is accessible without
authentication.  It is possible to put basic password auth on ironic&#8217;s API by
changing the nginx configuration accordingly.<ul>
<li>Bifrost playbooks can leverage and optionally install keystone.
See <a class="reference internal" href="deploy/keystone.html#keystone"><span>Bifrost with Keystone</span></a>.</li>
</ul>
</li>
<li>Neutron is NOT installed. Ironic performs static IP injection via
config-drive.</li>
<li>dnsmasq is configured statically and responds to all PXE boot requests by
chain-loading to iPXE, which then fetches the ironic-python-agent ramdisk
from Nginx.</li>
<li>Deployments are performed by the Ironic Python Agent, which as configured
supports IPMI, iLO, and UCS drivers.</li>
<li>By default, installation will build an Ubuntu-based image for deployment
to nodes.  This image can be easily customized if so desired.</li>
</ul>
<p>The re-execution of the playbook will cause states to be re-asserted.  If not
already present, a number of software packages including MySQL and RabbitMQ
will be installed on the host.  Python code will be reinstalled regardless if
it has changed, RabbitMQ user passwords will be reset, and services will be
restarted.</p>
<p>Run:</p>
<div class="highlight-python"><div class="highlight"><pre><span></span>If you have passwordless sudo enabled, run:
   ansible-playbook -vvvv -i inventory/target install.yaml
Otherwise, add -K option to let Ansible prompting for the sudo  password:
   ansible-playbook -K -vvvv -i inventory/target install.yaml
</pre></div>
</div>
<p>With regard to testing, ironic&#8217;s node cleaning capability is disabled by
default as it can be an unexpected surprise for a new user that their test
node is unusable for however long it takes for the disks to be wiped.</p>
<p>If you wish to enable cleaning, you can achieve this by passing the option
<code class="docutils literal"><span class="pre">-e</span> <span class="pre">cleaning=true</span></code> to the command line or executing the command below:</p>
<div class="highlight-python"><div class="highlight"><pre><span></span>ansible-playbook -K -vvvv -i inventory/target install.yaml -e cleaning=true
</pre></div>
</div>
<p>After you have performed an installation, you can edit /etc/ironic/ironic.conf
to enable or disable cleaning as desired, however it is highly encouraged to
utilize cleaning in any production environment.</p>
<p>The ironic community maintains a repository additional of drivers outside ironic.
These drivers and information about them can be found <a class="reference external" href="http://git.openstack.org/cgit/openstack/ironic-staging-drivers/">here</a>.
If you would like to install the ironic staging drivers, simply pass
<code class="docutils literal"><span class="pre">-e</span> <span class="pre">staging_drivers_include=true</span></code> when executing the install playbook:</p>
<div class="highlight-python"><div class="highlight"><pre><span></span>ansible-playbook -K -vvvv -i inventory/target install.yaml -e staging_drivers_include=true
</pre></div>
</div>
<div class="section" id="manual-cli-use">
<h3>Manual CLI use<a class="headerlink" href="#manual-cli-use" title="Permalink to this headline">¶</a></h3>
<p>If you wish to utilize ironic&#8217;s CLI in no-auth mode, you must set two
environment variables:</p>
<ul class="simple">
<li><code class="docutils literal"><span class="pre">IRONIC_URL</span></code> - A URL to the ironic API, such as <a class="reference external" href="http://localhost:6385/">http://localhost:6385/</a></li>
<li><code class="docutils literal"><span class="pre">OS_AUTH_TOKEN</span></code> - Any value except empty space, such as &#8216;fake-token&#8217;,
is required to cause the client library to send requests directly to the API.</li>
</ul>
<p>For your ease of use, <code class="docutils literal"><span class="pre">env-vars</span></code> can be sourced to allow the CLI to connect
to a local ironic installation operating in noauth mode. Run e.g.:</p>
<div class="highlight-python"><div class="highlight"><pre><span></span>source env-vars
ironic node-list
+------+------+---------------+-------------+--------------------+-------------+
| UUID | Name | Instance UUID | Power State | Provisioning State | Maintenance |
+------+------+---------------+-------------+--------------------+-------------+
+------+------+---------------+-------------+--------------------+-------------+
</pre></div>
</div>
<p>which should print an empty table if connection to Ironic works as expected.</p>
</div>
</div>
<div class="section" id="hardware-enrollment">
<h2>Hardware enrollment<a class="headerlink" href="#hardware-enrollment" title="Permalink to this headline">¶</a></h2>
<p>The following requirements are installed during the <a class="reference internal" href="#installation">Installation</a> step
above:</p>
<ul class="simple">
<li>openstack-infra/shade library</li>
<li>openstack-infra/os-client-config</li>
</ul>
<p>In order to enroll hardware, you will naturally need an inventory of
your hardware. When utilizing the dynamic inventory module and
accompanying roles the inventory can be supplied in one of three ways,
all of which ultimately translate to JSON data that Ansible parses.</p>
<p>The original method is to utilize a CSV file. This format is covered below in
the <a class="reference internal" href="#legacy-csv-file-format">Legacy CSV File Format</a> section. This has a number of limitations, but
does allow a user to bulk load hardware from an inventory list with minimal
data transformations.</p>
<p>The newer method is to utilize a JSON or YAML document which the inventory
parser will convert and provide to Ansible.</p>
<p>In order to use, you will need to define the environment variable
<code class="docutils literal"><span class="pre">BIFROST_INVENTORY_SOURCE</span></code> to equal a file, which then allows you to
execute Ansible utilizing the <code class="docutils literal"><span class="pre">bifrost_inventory.py</span></code> file as the data
source.</p>
<div class="section" id="conversion-from-csv-to-json-formats">
<h3>Conversion from CSV to JSON formats<a class="headerlink" href="#conversion-from-csv-to-json-formats" title="Permalink to this headline">¶</a></h3>
<p>The <code class="docutils literal"><span class="pre">inventory/bifrost_inventory.py</span></code> program additionally features a
mode that allows a user to convert a CSV file to the JSON data format
utilizing a <code class="docutils literal"><span class="pre">--convertcsv</span></code> command line setting when directly invoked.</p>
<p>Example:</p>
<div class="highlight-python"><div class="highlight"><pre><span></span>export BIFROST_INVENTORY_SOURCE=/tmp/baremetal.csv
inventory/bifrost_inventory.py --convertcsv &gt;/tmp/baremetal.json
</pre></div>
</div>
</div>
<div class="section" id="json-file-format">
<h3>JSON file format<a class="headerlink" href="#json-file-format" title="Permalink to this headline">¶</a></h3>
<p>The JSON format closely resembles the data structure that ironic
utilizes internally.  The <code class="docutils literal"><span class="pre">name</span></code>, <code class="docutils literal"><span class="pre">driver_info</span></code>, <code class="docutils literal"><span class="pre">nics</span></code>,
<code class="docutils literal"><span class="pre">driver</span></code>, and <code class="docutils literal"><span class="pre">properties</span></code> fields are directly mapped through to
ironic.  This means that the data contained within can vary from host
to host, such as drivers and their parameters thus allowing a mixed
hardware environment to be defined in a single file.</p>
<p>Example:</p>
<div class="highlight-python"><div class="highlight"><pre><span></span><span class="p">{</span>
    <span class="s2">&quot;testvm1&quot;</span><span class="p">:</span> <span class="p">{</span>
      <span class="s2">&quot;uuid&quot;</span><span class="p">:</span> <span class="s2">&quot;00000000-0000-0000-0000-000000000001&quot;</span><span class="p">,</span>
      <span class="s2">&quot;driver_info&quot;</span><span class="p">:</span> <span class="p">{</span>
        <span class="s2">&quot;power&quot;</span><span class="p">:</span> <span class="p">{</span>
          <span class="s2">&quot;ssh_port&quot;</span><span class="p">:</span> <span class="mi">22</span><span class="p">,</span>
          <span class="s2">&quot;ssh_username&quot;</span><span class="p">:</span> <span class="s2">&quot;ironic&quot;</span><span class="p">,</span>
          <span class="s2">&quot;ssh_virt_type&quot;</span><span class="p">:</span> <span class="s2">&quot;virsh&quot;</span><span class="p">,</span>
          <span class="s2">&quot;ssh_address&quot;</span><span class="p">:</span> <span class="s2">&quot;192.168.122.1&quot;</span><span class="p">,</span>
          <span class="s2">&quot;ssh_key_filename&quot;</span><span class="p">:</span> <span class="s2">&quot;/home/ironic/.ssh/id_rsa&quot;</span>
        <span class="p">}</span>
      <span class="p">},</span>
      <span class="s2">&quot;nics&quot;</span><span class="p">:</span> <span class="p">[</span>
        <span class="p">{</span>
          <span class="s2">&quot;mac&quot;</span><span class="p">:</span> <span class="s2">&quot;52:54:00:f9:32:f6&quot;</span>
        <span class="p">}</span>
      <span class="p">],</span>
      <span class="s2">&quot;driver&quot;</span><span class="p">:</span> <span class="s2">&quot;agent_ssh&quot;</span><span class="p">,</span>
      <span class="s2">&quot;ansible_ssh_host&quot;</span><span class="p">:</span> <span class="s2">&quot;192.168.122.2&quot;</span><span class="p">,</span>
      <span class="s2">&quot;ipv4_address&quot;</span><span class="p">:</span> <span class="s2">&quot;192.168.122.2&quot;</span><span class="p">,</span>
      <span class="s2">&quot;provisioning_ipv4_address&quot;</span><span class="p">:</span> <span class="s2">&quot;10.0.0.9&quot;</span><span class="p">,</span>
      <span class="s2">&quot;properties&quot;</span><span class="p">:</span> <span class="p">{</span>
        <span class="s2">&quot;cpu_arch&quot;</span><span class="p">:</span> <span class="s2">&quot;x86_64&quot;</span><span class="p">,</span>
        <span class="s2">&quot;ram&quot;</span><span class="p">:</span> <span class="s2">&quot;3072&quot;</span><span class="p">,</span>
        <span class="s2">&quot;disk_size&quot;</span><span class="p">:</span> <span class="s2">&quot;10&quot;</span><span class="p">,</span>
        <span class="s2">&quot;cpus&quot;</span><span class="p">:</span> <span class="s2">&quot;1&quot;</span>
      <span class="p">},</span>
      <span class="s2">&quot;name&quot;</span><span class="p">:</span> <span class="s2">&quot;testvm1&quot;</span>
    <span class="p">}</span>
<span class="p">}</span>
</pre></div>
</div>
<p>The additional power of this format is easy configuration parameter injection,
which could potentially allow a user to provision different operating system
images onto different hardware chassis by defining the appropriate settings
in an <code class="docutils literal"><span class="pre">instance_info</span></code> variable.</p>
<p>Examples utilizing JSON and YAML formatting, along host specific variable
injection can be found in the <code class="docutils literal"><span class="pre">playbooks/inventory/</span></code> folder.</p>
</div>
<div class="section" id="legacy-csv-file-format">
<h3>Legacy CSV file format<a class="headerlink" href="#legacy-csv-file-format" title="Permalink to this headline">¶</a></h3>
<p>The CSV file has the following columns:</p>
<ol class="arabic simple" start="0">
<li>MAC Address</li>
<li>Management username</li>
<li>Management password</li>
<li>Management Address</li>
<li>CPU Count</li>
<li>Memory size in MB</li>
<li>Disk Storage in GB</li>
<li>Flavor (Not Used)</li>
<li>Type (Not Used)</li>
<li>Host UUID</li>
<li>Host or Node name</li>
<li>Host IP Address to be set</li>
<li><code class="docutils literal"><span class="pre">ipmi_target_channel</span></code> - Requires: <code class="docutils literal"><span class="pre">ipmi_bridging</span></code> set to single</li>
<li><code class="docutils literal"><span class="pre">ipmi_target_address</span></code> - Requires: <code class="docutils literal"><span class="pre">ipmi_bridging</span></code> set to single</li>
<li><code class="docutils literal"><span class="pre">ipmi_transit_channel</span></code> - Requires: <code class="docutils literal"><span class="pre">ipmi_bridging</span></code> set to dual</li>
<li><code class="docutils literal"><span class="pre">ipmi_transit_address</span></code> - Requires: <code class="docutils literal"><span class="pre">ipmi_bridging</span></code> set to dual</li>
<li>ironic driver</li>
<li>Host provisioning IP Address</li>
</ol>
<p>Example definition:</p>
<div class="highlight-python"><div class="highlight"><pre><span></span>00:11:22:33:44:55,root,undefined,192.168.122.1,1,8192,512,NA,NA,aaaaaaaa-bbbb-cccc-dddd-eeeeeeeeeeee,hostname_100,192.168.2.100,,,,agent_ipmitool,10.0.0.9
</pre></div>
</div>
<p>This file format is fairly flexible and can be easily modified
although the enrollment and deployment playbooks utilize the model
of a host per line model in order to process through the entire
list, as well as reference the specific field items.</p>
<p>An example file can be found at: <code class="docutils literal"><span class="pre">playbooks/inventory/baremetal.csv.example</span></code></p>
</div>
<div class="section" id="how-this-works">
<h3>How this works?<a class="headerlink" href="#how-this-works" title="Permalink to this headline">¶</a></h3>
<p>Utilizing the dynamic inventory module, enrollment is as simple as setting
the <code class="docutils literal"><span class="pre">BIFROST_INVENTORY_SOURCE</span></code> environment variable to your inventory data
source, and then executing the enrollment playbook.:</p>
<div class="highlight-python"><div class="highlight"><pre><span></span>export BIFROST_INVENTORY_SOURCE=/tmp/baremetal.json
ansible-playbook -vvvv -i inventory/bifrost_inventory.py enroll-dynamic.yaml
</pre></div>
</div>
<p>When ironic is installed on remote server, a regular ansible inventory
with a target server should be added to ansible. This can be achieved by
specifying a directory with files, each file in that directory will be part of
the ansible inventory. Refer to ansible documentation
<a class="reference external" href="http://docs.ansible.com/ansible/intro_dynamic_inventory.html#using-inventory-directories-and-multiple-inventory-sources">http://docs.ansible.com/ansible/intro_dynamic_inventory.html#using-inventory-directories-and-multiple-inventory-sources</a></p>
<div class="highlight-python"><div class="highlight"><pre><span></span>export BIFROST_INVENTORY_SOURCE=/tmp/baremetal.json
rm inventory/*.example
ansible-playbook -vvvv -i inventory/ enroll-dynamic.yaml
</pre></div>
</div>
<p>Note that enrollment is a one-time operation. The Ansible module <em>does not</em>
synchronize data for existing nodes.  You should use the ironic CLI to do this
manually at the moment.</p>
<p>Additionally, it is important to note that the playbooks for enrollment are
split into three separate playbooks based on the <code class="docutils literal"><span class="pre">ipmi_bridging</span></code> setting.</p>
</div>
</div>
<div class="section" id="hardware-deployment">
<h2>Hardware deployment<a class="headerlink" href="#hardware-deployment" title="Permalink to this headline">¶</a></h2>
<div class="section" id="id1">
<h3>How this works?<a class="headerlink" href="#id1" title="Permalink to this headline">¶</a></h3>
<p>After the nodes are enrolled, they can be deployed upon.  Bifrost is geared to
utilize configuration drives to convey basic configuration information to the
each host. This configuration information includes an SSH key to allow a user
to login to the system.</p>
<p>To utilize the newer dynamic inventory based deployment:</p>
<div class="highlight-python"><div class="highlight"><pre><span></span>export BIFROST_INVENTORY_SOURCE=/tmp/baremetal.json
ansible-playbook -vvvv -i inventory/bifrost_inventory.py deploy-dynamic.yaml
</pre></div>
</div>
<p>When ironic is installed on remote server, a regular ansible inventory
with a target server should be added to ansible. This can be achieved by
specifying a directory with files, each file in that directory will be part of
the ansible inventory. Refer to ansible documentation
<a class="reference external" href="http://docs.ansible.com/ansible/intro_dynamic_inventory.html#using-inventory-directories-and-multiple-inventory-sources">http://docs.ansible.com/ansible/intro_dynamic_inventory.html#using-inventory-directories-and-multiple-inventory-sources</a></p>
<div class="highlight-python"><div class="highlight"><pre><span></span>export BIFROST_INVENTORY_SOURCE=/tmp/baremetal.json
rm inventory/*.example
ansible-playbook -vvvv -i inventory/ deploy-dynamic.yaml
</pre></div>
</div>
<p>Note:</p>
<div class="highlight-python"><div class="highlight"><pre><span></span>Before running the above command, ensure that the value for `ssh_public_key_path` in
``./playbooks/inventory/group_vars/baremetal`` refers to a valid public key file,
or set the ssh_public_key_path option on the ansible-playbook command line by
setting the variable. Example: &quot;-e ssh_public_key_path=~/.ssh/id_rsa.pub&quot;
</pre></div>
</div>
<p>If the hosts need to be re-deployed, the dynamic redeploy playbook may be used:</p>
<div class="highlight-python"><div class="highlight"><pre><span></span>export BIFROST_INVENTORY_SOURCE=/tmp/baremetal.json
ansible-playbook -vvvv -i inventory/bifrost_inventory.py redeploy-dynamic.yaml
</pre></div>
</div>
<p>This playbook will undeploy the hosts, followed by a deployment, allowing
a configurable timeout for the hosts to transition in each step.</p>
</div>
</div>
<div class="section" id="testing-with-a-single-command">
<h2>Testing with a single command<a class="headerlink" href="#testing-with-a-single-command" title="Permalink to this headline">¶</a></h2>
<p>A simple <code class="docutils literal"><span class="pre">scripts/test-bifrost.sh</span></code> script can be utilized to install
pre-requisite software packages, Ansible, and then execute the
<code class="docutils literal"><span class="pre">test-bifrost-create-vm.yaml</span></code> and <code class="docutils literal"><span class="pre">test-bifrost.yaml</span></code> playbooks in order
to provide a single step testing mechanism.</p>
<p><code class="docutils literal"><span class="pre">playbooks/test-bifrost-create-vm.yaml</span></code> creates one or more VMs for
testing and saves out a baremetal.csv file which is used by
<code class="docutils literal"><span class="pre">playbooks/test-bifrost.yaml</span></code> to execute the remaining roles.  Two
additional roles are invoked by this playbook which enables Ansible to
connect to the new nodes by adding them to the inventory, and then
logging into the remote machine via the user&#8217;s ssh host key.  Once
that has successfully occurred, additional roles will unprovision the
host(s) and delete them from ironic.</p>
<p>Command:</p>
<div class="highlight-python"><div class="highlight"><pre><span></span><span class="n">scripts</span><span class="o">/</span><span class="n">test</span><span class="o">-</span><span class="n">bifrost</span><span class="o">.</span><span class="n">sh</span>
</pre></div>
</div>
<p>Note:</p>
<ul class="simple">
<li>Cleaning mode is explicitly disabled in the <code class="docutils literal"><span class="pre">test-bifrost.yaml</span></code>
playbook due to the fact that is an IO-intensive operation that can
take a great deal of time.</li>
</ul>
</div>
<div class="section" id="legacy-testing-with-virtual-machines">
<h2>Legacy - testing with virtual machines<a class="headerlink" href="#legacy-testing-with-virtual-machines" title="Permalink to this headline">¶</a></h2>
<p>Bifrost supports using virtual machines to emulate the hardware. All of the
steps mentioned above are mostly the same.</p>
<p>It is assumed you have an SSH server running on the host machine. The
<code class="docutils literal"><span class="pre">agent_ssh</span></code> driver, used by ironic with VM testing, will need to use
SSH to control the virtual machines.</p>
<p>An SSH key is generated for the <code class="docutils literal"><span class="pre">ironic</span></code> user when testing. The
ironic conductor will use this key to connect to the host machine and
run virsh commands.</p>
<ol class="arabic simple">
<li>Set <code class="docutils literal"><span class="pre">testing</span></code> to <em>true</em> in the
<code class="docutils literal"><span class="pre">playbooks/inventory/group_vars/target</span></code> file.</li>
<li>You may need to adjust the value for <code class="docutils literal"><span class="pre">ssh_public_key_path</span></code>.</li>
<li>Run the install step, as documented above, however adding <code class="docutils literal"><span class="pre">-e</span>
<span class="pre">testing=true</span></code> to the Ansible command line.</li>
<li>Execute the <code class="docutils literal"><span class="pre">ansible-playbook</span> <span class="pre">-vvvv</span> <span class="pre">-i</span> <span class="pre">inventory/target</span>
<span class="pre">test-bifrost-create-vm.yaml</span></code> command to create a test virtual
machine.</li>
<li>Set the environment variable of <code class="docutils literal"><span class="pre">BIFROST_INVENTORY_SOURCE</span></code> to the
path to the csv file, which by default has been written to
/tmp/baremetal.csv.</li>
<li>Run the enrollment step, as documented above, using the CSV file
you created in the previous step.</li>
<li>Run the deployment step, as documented above.</li>
</ol>
</div>
<div class="section" id="deployment-and-configuration-of-operating-systems">
<h2>Deployment and configuration of operating systems<a class="headerlink" href="#deployment-and-configuration-of-operating-systems" title="Permalink to this headline">¶</a></h2>
<p>By default, Bifrost deploys a configuration drive which includes the user SSH
public key, hostname, and the network configuration in the form of
network_data.json that can be read/parsed by the
<a class="reference external" href="https://github.com/openstack-infra/glean">glean</a> utility. This allows for
the deployment of Ubuntu, CentOS, or Fedora &#8220;tenants&#8221; on baremetal.  This file
format is not yet supported by Cloud-Init, however it is on track for
inclusion in cloud-init 2.0.</p>
<p>By default, Bifrost utilizes a utility called simple-init which leverages
the previously noted glean utility to apply network configuration.  This
means that by default, root file systems may not be automatically expanded
to consume the entire disk, which may, or may not be desirable depending
upon operational needs. This is dependent upon what base OS image you
utilize, and if the support is included in that image or not.  At present,
the standard Ubuntu cloud image includes cloud-init which will grow the
root partition, however the ubuntu-minimal image does not include cloud-init
and thus will not automatically grow the root partition.</p>
<p>Due to the nature of the design, it would be relatively easy for a user to
import automatic growth or reconfiguration steps either in the image to be
deployed, or in post-deployment steps via custom Ansible playbooks.</p>
</div>
<div class="section" id="custom-ipa-images">
<h2>Custom IPA images<a class="headerlink" href="#custom-ipa-images" title="Permalink to this headline">¶</a></h2>
<p>Bifrost supports the ability for a user to build a custom IPA ramdisk
utilizing the diskimage-builder element &#8220;ironic-agent&#8221;.  In order to utilize
this feature, the <code class="docutils literal"><span class="pre">download_ipa</span></code> setting must be set to <code class="docutils literal"><span class="pre">false</span></code> and the
create_ipa_image must be set to &#8220;true&#8221;.  By default, the install playbook will
build a Debian jessie based IPA image, if a pre-existing IPA image is not
present on disk.  If you wish to explicitly set a specific release to be
passed to diskimage-create, then the setting <code class="docutils literal"><span class="pre">dib_os_release</span></code> can be set in
addition to <code class="docutils literal"><span class="pre">dib_os_element</span></code>.</p>
<p>If you wish to include an extra element into the IPA disk image, such as a
custom hardware manager, you can pass the variable <code class="docutils literal"><span class="pre">ipa_extra_dib_elements</span></code>
as a space-separated list of elements. This defaults to an empty string.</p>
</div>
<div class="section" id="driver-support">
<h2>Driver Support<a class="headerlink" href="#driver-support" title="Permalink to this headline">¶</a></h2>
<div class="section" id="testing-mode">
<h3>Testing Mode<a class="headerlink" href="#testing-mode" title="Permalink to this headline">¶</a></h3>
<p>When setup in testing mode, bifrost configures ironic to utilize the
<code class="docutils literal"><span class="pre">agent_ssh</span></code> driver to help facilitate the deployment of local test
machines.</p>
</div>
<div class="section" id="default-mode">
<h3>Default Mode<a class="headerlink" href="#default-mode" title="Permalink to this headline">¶</a></h3>
<p>When not in testing mode, bifrost enables the following ironic drivers:</p>
<ul class="simple">
<li>agent_ipmitool</li>
<li>agent_ilo</li>
<li>agent_ucs</li>
</ul>
</div>
<div class="section" id="oneview-driver-support">
<h3>OneView Driver Support<a class="headerlink" href="#oneview-driver-support" title="Permalink to this headline">¶</a></h3>
<p>As the OneView driver requires configuration information to be populated
in the ironic.conf configuration file that points to the OneView manager
node as well as credentials, bifrost does not support installation and
configuration of the driver.</p>
<p>Please reference the ironic OneView driver documentation at if you wish
to update the configuration after installation in order to leverage bifrost
for mass node deployment.</p>
<p>The OneView documentation can be found
<a class="reference external" href="http://docs.openstack.org/developer/ironic/drivers/oneview.html">here</a>.</p>
</div>
</div>
<div class="section" id="virtualenv-installation-support-experimental">
<h2>Virtualenv installation support (EXPERIMENTAL)<a class="headerlink" href="#virtualenv-installation-support-experimental" title="Permalink to this headline">¶</a></h2>
<p>Bifrost can be used with a python virtual environment. At present,
this feature is experimental, so it&#8217;s disabled by default. If you
would like to use a virtual environment, you&#8217;ll need to modify the
install steps slightly. To set up the virtual environment and install
ansible into it, run <code class="docutils literal"><span class="pre">env-setup.sh</span></code> as follows:</p>
<div class="highlight-python"><div class="highlight"><pre><span></span>export VENV=/opt/stack/bifrost
./scripts/env-setup.sh
</pre></div>
</div>
<p>Then run the install playbook with the following arguments:</p>
<div class="highlight-python"><div class="highlight"><pre><span></span>ansible-playbook -vvvv -i inventory/target install.yaml
</pre></div>
</div>
<p>This will install ironic and its dependencies into the virtual environment.</p>
</div>
</div>


          </div>
        </div>
      </div>
<div class="sphinxsidebar">
    <div class="sphinxsidebarwrapper">
            <h3><a href="index.html">Table Of Contents</a></h3>
            <ul>
<li><a class="reference internal" href="#">Team and repository tags</a><ul>
<li><a class="reference internal" href="#bifrost">Bifrost</a></li>
<li><a class="reference internal" href="#use-cases">Use Cases</a></li>
<li><a class="reference internal" href="#use">Use</a></li>
<li><a class="reference internal" href="#pre-install-steps">Pre-install steps</a><ul>
<li><a class="reference internal" href="#enable-additional-repositories-rhel-only">Enable additional repositories (RHEL only)</a></li>
<li><a class="reference internal" href="#enable-the-epel-repository-rhel">Enable the EPEL repository (RHEL)</a></li>
<li><a class="reference internal" href="#enable-the-epel-repository-centos">Enable the EPEL repository (CentOS)</a></li>
</ul>
</li>
<li><a class="reference internal" href="#installation">Installation</a><ul>
<li><a class="reference internal" href="#manual-cli-use">Manual CLI use</a></li>
</ul>
</li>
<li><a class="reference internal" href="#hardware-enrollment">Hardware enrollment</a><ul>
<li><a class="reference internal" href="#conversion-from-csv-to-json-formats">Conversion from CSV to JSON formats</a></li>
<li><a class="reference internal" href="#json-file-format">JSON file format</a></li>
<li><a class="reference internal" href="#legacy-csv-file-format">Legacy CSV file format</a></li>
<li><a class="reference internal" href="#how-this-works">How this works?</a></li>
</ul>
</li>
<li><a class="reference internal" href="#hardware-deployment">Hardware deployment</a><ul>
<li><a class="reference internal" href="#id1">How this works?</a></li>
</ul>
</li>
<li><a class="reference internal" href="#testing-with-a-single-command">Testing with a single command</a></li>
<li><a class="reference internal" href="#legacy-testing-with-virtual-machines">Legacy - testing with virtual machines</a></li>
<li><a class="reference internal" href="#deployment-and-configuration-of-operating-systems">Deployment and configuration of operating systems</a></li>
<li><a class="reference internal" href="#custom-ipa-images">Custom IPA images</a></li>
<li><a class="reference internal" href="#driver-support">Driver Support</a><ul>
<li><a class="reference internal" href="#testing-mode">Testing Mode</a></li>
<li><a class="reference internal" href="#default-mode">Default Mode</a></li>
<li><a class="reference internal" href="#oneview-driver-support">OneView Driver Support</a></li>
</ul>
</li>
<li><a class="reference internal" href="#virtualenv-installation-support-experimental">Virtualenv installation support (EXPERIMENTAL)</a></li>
</ul>
</li>
</ul>

            <h4>Previous topic</h4>
            <p class="topless"><a href="index.html"
                                  title="previous chapter">Welcome to bifrost&#8217;s documentation!</a></p>
            <h4>Next topic</h4>
            <p class="topless"><a href="contributing.html"
                                  title="next chapter">Contributing</a></p>
            <h3>Project Source</h3>
            <ul class="this-page-menu">
              <li><a href="http://git.openstack.org/cgit/openstack/bifrost
"
                     rel="nofollow">Project Source</a></li>
            </ul>
            <h3>This Page</h3>
            <ul class="this-page-menu">
              <li><a href="_sources/readme.txt"
                     rel="nofollow">Show Source</a></li>
            </ul>
          <div id="searchbox" style="display: none">
            <h3>Quick search</h3>
              <form class="search" action="search.html" method="get">
                <input type="text" name="q" size="18" />
                <input type="submit" value="Go" />
                <input type="hidden" name="check_keywords" value="yes" />
                <input type="hidden" name="area" value="default" />
              </form>
              <p class="searchtip" style="font-size: 90%">
              Enter search terms or a module, class or function name.
              </p>
          </div>
          <script type="text/javascript">$('#searchbox').show(0);</script>
    </div>
</div>

      <div class="clearer"></div>
    </div>
    <div class="related" role="navigation" aria-label="related navigation">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="genindex.html" title="General Index"
             accesskey="I">index</a></li>
        <li class="right" >
          <a href="contributing.html" title="Contributing"
             accesskey="N">next</a> |</li>
        <li class="right" >
          <a href="index.html" title="Welcome to bifrost’s documentation!"
             accesskey="P">previous</a> |</li>
        <li class="nav-item nav-item-0"><a href="index.html">bifrost 3.0.1.dev1 documentation</a> &raquo;</li> 
      </ul>
    </div>

    <div class="footer" role="contentinfo">
        &copy; Copyright 2015, OpenStack Foundation.
      Created using <a href="http://sphinx-doc.org/">Sphinx</a> 1.3.6.
    </div>
<script type="text/javascript">
var gaJsHost = (("https:" == document.location.protocol) ? "https://ssl." : "http://www.");
document.write(unescape("%3Cscript src='" + gaJsHost + "google-analytics.com/ga.js' type='text/javascript'%3E%3C/script%3E"));
</script>
<script type="text/javascript">
try {
//Tracking docs.openstack.org/developer/<projectname> only
//The URL is built from the project variable in conf.py
var pageTracker = _gat._getTracker("UA-17511903-1");
pageTracker._setCookiePath("/developer/bifrost");
pageTracker._trackPageview();
} catch(err) {}</script>

  </body>
</html>