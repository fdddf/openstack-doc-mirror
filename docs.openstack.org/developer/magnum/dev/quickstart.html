<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN"
  "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">


<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    
    <title>Developer Quick-Start &mdash; magnum 4.0.1.dev40 documentation</title>
    
    <link rel="stylesheet" href="../_static/nature.css" type="text/css" />
    <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
    <link rel="stylesheet" href="../_static/tweaks.css" type="text/css" />
    
    <script type="text/javascript">
      var DOCUMENTATION_OPTIONS = {
        URL_ROOT:    '../',
        VERSION:     '4.0.1.dev40',
        COLLAPSE_INDEX: false,
        FILE_SUFFIX: '.html',
        HAS_SOURCE:  true
      };
    </script>
    <script type="text/javascript" src="../_static/jquery.js"></script>
    <script type="text/javascript" src="../_static/underscore.js"></script>
    <script type="text/javascript" src="../_static/doctools.js"></script>
    <link rel="top" title="magnum 4.0.1.dev40 documentation" href="../index.html" />
    <link rel="next" title="Cluster Type Definition" href="cluster-type-definition.html" />
    <link rel="prev" title="Welcome to Magnum’s Developer Documentation!" href="../index.html" /> 
  </head>
  <body role="document">
  <div id="header">
    <h1 id="logo"><a href="http://www.openstack.org/">OpenStack</a></h1>
    <ul id="navigation">
      
      <li><a href="http://www.openstack.org/" title="Go to the Home page" class="link">Home</a></li>
      <li><a href="http://www.openstack.org/projects/" title="Go to the OpenStack Projects page">Projects</a></li>
      <li><a href="http://www.openstack.org/user-stories/" title="Go to the User Stories page" class="link">User Stories</a></li>
      <li><a href="http://www.openstack.org/community/" title="Go to the Community page" class="link">Community</a></li>
      <li><a href="http://www.openstack.org/blog/" title="Go to the OpenStack Blog">Blog</a></li>
      <li><a href="http://wiki.openstack.org/" title="Go to the OpenStack Wiki">Wiki</a></li>
      <li><a href="http://docs.openstack.org/" title="Go to OpenStack Documentation" class="current">Documentation</a></li>
      
    </ul>
  </div>
  

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          <div class="body" role="main">
            
  <div class="section" id="developer-quick-start">
<span id="quickstart"></span><h1>Developer Quick-Start<a class="headerlink" href="#developer-quick-start" title="Permalink to this headline">¶</a></h1>
<p>This is a quick walkthrough to get you started developing code for magnum.
This assumes you are already familiar with submitting code reviews to an
OpenStack project.</p>
<div class="admonition seealso">
<p class="first admonition-title">See also</p>
<p class="last"><a class="reference external" href="http://docs.openstack.org/infra/manual/developers.html">http://docs.openstack.org/infra/manual/developers.html</a></p>
</div>
<div class="section" id="setup-dev-environment">
<h2>Setup Dev Environment<a class="headerlink" href="#setup-dev-environment" title="Permalink to this headline">¶</a></h2>
<p>Install OS-specific prerequisites:</p>
<div class="highlight-python"><div class="highlight"><pre><span></span># Ubuntu/Debian:
sudo apt-get update
sudo apt-get install -y python-dev libssl-dev libxml2-dev \
                        libmysqlclient-dev libxslt-dev libpq-dev git \
                        libffi-dev gettext build-essential python3.4-dev

# Fedora/RHEL:
sudo yum install -y python-devel openssl-devel mysql-devel \
                    libxml2-devel libxslt-devel postgresql-devel git \
                    libffi-devel gettext gcc

# openSUSE/SLE 12:
sudo zypper --non-interactive install git libffi-devel \
                    libmysqlclient-devel libopenssl-devel libxml2-devel \
                    libxslt-devel postgresql-devel python-devel \
                    gettext-runtime
</pre></div>
</div>
<p>Install pip:</p>
<div class="highlight-python"><div class="highlight"><pre><span></span>curl -s https://bootstrap.pypa.io/get-pip.py | sudo python
</pre></div>
</div>
<p>Install common prerequisites:</p>
<div class="highlight-python"><div class="highlight"><pre><span></span>sudo pip install virtualenv flake8 tox testrepository git-review
</pre></div>
</div>
<p>You may need to explicitly upgrade virtualenv if you&#8217;ve installed the one
from your OS distribution and it is too old (tox will complain). You can
upgrade it individually, if you need to:</p>
<div class="highlight-python"><div class="highlight"><pre><span></span>sudo pip install -U virtualenv
</pre></div>
</div>
<p>Magnum source code should be pulled directly from git:</p>
<div class="highlight-python"><div class="highlight"><pre><span></span># from your home or source directory
cd ~
git clone https://git.openstack.org/openstack/magnum
cd magnum
</pre></div>
</div>
<p>All unit tests should be run using tox. To run magnum&#8217;s entire test suite:</p>
<div class="highlight-python"><div class="highlight"><pre><span></span><span class="c1"># run all tests (unit and pep8)</span>
<span class="n">tox</span>
</pre></div>
</div>
<p>To run a specific test, use a positional argument for the unit tests:</p>
<div class="highlight-python"><div class="highlight"><pre><span></span><span class="c1"># run a specific test for Python 2.7</span>
<span class="n">tox</span> <span class="o">-</span><span class="n">epy27</span> <span class="o">--</span> <span class="n">test_conductor</span>
</pre></div>
</div>
<p>You may pass options to the test programs using positional arguments:</p>
<div class="highlight-python"><div class="highlight"><pre><span></span><span class="c1"># run all the Python 2.7 unit tests (in parallel!)</span>
<span class="n">tox</span> <span class="o">-</span><span class="n">epy27</span> <span class="o">--</span> <span class="o">--</span><span class="n">parallel</span>
</pre></div>
</div>
<p>To run only the pep8/flake8 syntax and style checks:</p>
<div class="highlight-python"><div class="highlight"><pre><span></span><span class="n">tox</span> <span class="o">-</span><span class="n">epep8</span>
</pre></div>
</div>
<p>To run unit test coverage and check percentage of code covered:</p>
<div class="highlight-python"><div class="highlight"><pre><span></span>tox -e cover
</pre></div>
</div>
<p>To discover and interact with templates, please refer to
<a class="reference external" href="http://docs.openstack.org/developer/magnum/dev/bay-template-example.html">http://docs.openstack.org/developer/magnum/dev/bay-template-example.html</a></p>
</div>
<div class="section" id="exercising-the-services-using-devstack">
<h2>Exercising the Services Using Devstack<a class="headerlink" href="#exercising-the-services-using-devstack" title="Permalink to this headline">¶</a></h2>
<p>Devstack can be configured to enable magnum support. It is easy to develop
magnum with the devstack environment. Magnum depends on nova, glance, heat and
neutron to create and schedule virtual machines to simulate bare-metal (full
bare-metal support is under active development).</p>
<p><strong>NOTE:</strong> Running devstack within a virtual machine with magnum enabled is not
recommended at this time.</p>
<p>This session has only been tested on Ubuntu 14.04 (Trusty) and Fedora 20/21.
We recommend users to select one of them if it is possible.</p>
<p>Clone devstack:</p>
<div class="highlight-python"><div class="highlight"><pre><span></span># Create a root directory for devstack if needed
sudo mkdir -p /opt/stack
sudo chown $USER /opt/stack

git clone https://git.openstack.org/openstack-dev/devstack /opt/stack/devstack
</pre></div>
</div>
<p>We will run devstack with minimal local.conf settings required to enable
magnum, heat, and neutron (neutron is enabled by default in devstack since
Kilo, and heat must be enabled by yourself):</p>
<div class="highlight-python"><div class="highlight"><pre><span></span>cat &gt; /opt/stack/devstack/local.conf &lt;&lt; END
[[local|localrc]]
DATABASE_PASSWORD=password
RABBIT_PASSWORD=password
SERVICE_TOKEN=password
SERVICE_PASSWORD=password
ADMIN_PASSWORD=password
# magnum requires the following to be set correctly
PUBLIC_INTERFACE=eth1

# Enable barbican service and use it to store TLS certificates
# For details http://docs.openstack.org/developer/magnum/dev/tls.html
enable_plugin barbican https://git.openstack.org/openstack/barbican

enable_plugin heat https://git.openstack.org/openstack/heat

# Enable magnum plugin after dependent plugins
enable_plugin magnum https://git.openstack.org/openstack/magnum

# Optional:  uncomment to enable the Magnum UI plugin in Horizon
#enable_plugin magnum-ui https://github.com/openstack/magnum-ui

VOLUME_BACKING_FILE_SIZE=20G
END
</pre></div>
</div>
<p><strong>NOTE:</strong> Update PUBLIC_INTERFACE as appropriate for your system.</p>
<p><strong>NOTE:</strong> Enable heat plugin is necessary.</p>
<p>Optionally, you can enable neutron/lbaas v2 with octavia to create load
balancers for multi master clusters:</p>
<div class="highlight-python"><div class="highlight"><pre><span></span>cat &gt;&gt; /opt/stack/devstack/local.conf &lt;&lt; END
enable_plugin neutron-lbaas https://git.openstack.org/openstack/neutron-lbaas
enable_plugin octavia https://git.openstack.org/openstack/octavia

# Disable LBaaS(v1) service
disable_service q-lbaas
# Enable LBaaS(v2) services
enable_service q-lbaasv2
enable_service octavia
enable_service o-cw
enable_service o-hk
enable_service o-hm
enable_service o-api
END
</pre></div>
</div>
<p>Optionally, you can enable ceilometer in devstack. If ceilometer is enabled,
magnum will periodically send metrics to ceilometer:</p>
<div class="highlight-python"><div class="highlight"><pre><span></span>cat &gt;&gt; /opt/stack/devstack/local.conf &lt;&lt; END
enable_plugin ceilometer https://git.openstack.org/openstack/ceilometer
END
</pre></div>
</div>
<p>If you want to deploy Docker Registry 2.0 in your cluster, you should enable
swift in devstack:</p>
<div class="highlight-python"><div class="highlight"><pre><span></span>cat &gt;&gt; /opt/stack/devstack/local.conf &lt;&lt; END
enable_service s-proxy
enable_service s-object
enable_service s-container
enable_service s-account
END
</pre></div>
</div>
<p>More devstack configuration information can be found at
<a class="reference external" href="http://docs.openstack.org/developer/devstack/configuration.html">http://docs.openstack.org/developer/devstack/configuration.html</a></p>
<p>More neutron configuration information can be found at
<a class="reference external" href="http://docs.openstack.org/developer/devstack/guides/neutron.html">http://docs.openstack.org/developer/devstack/guides/neutron.html</a></p>
<p>Run devstack:</p>
<div class="highlight-python"><div class="highlight"><pre><span></span>cd /opt/stack/devstack
./stack.sh
</pre></div>
</div>
<p><strong>NOTE:</strong> This will take a little extra time when the Fedora Atomic micro-OS
image is downloaded for the first time.</p>
<p>At this point, two magnum process (magnum-api and magnum-conductor) will be
running on devstack screens. If you make some code changes and want to
test their effects, just stop and restart magnum-api and/or magnum-conductor.</p>
<p>Prepare your session to be able to use the various openstack clients including
magnum, neutron, and glance. Create a new shell, and source the devstack openrc
script:</p>
<div class="highlight-python"><div class="highlight"><pre><span></span>source /opt/stack/devstack/openrc admin admin
</pre></div>
</div>
<p>Magnum has been tested with the Fedora Atomic micro-OS and CoreOS. Magnum will
likely work with other micro-OS platforms, but each requires individual
support in the heat template.</p>
<p>The Fedora Atomic micro-OS image will automatically be added to glance.  You
can add additional images manually through glance. To verify the image created
when installing devstack use:</p>
<div class="highlight-python"><div class="highlight"><pre><span></span>glance -v image-list

+--------------------------------------+---------------------------------+-------------+------------------+-----------+--------+----------------------------------+
| ID                                   | Name                            | Disk_format | Container_format | Size      | Status | Owner                            |
+--------------------------------------+---------------------------------+-------------+------------------+-----------+--------+----------------------------------+
| 090de3a2-2c0c-42d5-b5a3-cfcddd6d011b | cirros-0.3.4-x86_64-uec         | ami         | ami              | 25165824  | active | f98b9727094d40c78b1ed40e3bc91e80 |
| 9501d296-f0aa-4c0e-bc24-2a680f8741f0 | cirros-0.3.4-x86_64-uec-kernel  | aki         | aki              | 4979632   | active | f98b9727094d40c78b1ed40e3bc91e80 |
| 01478d1a-59e0-4f36-b69e-0eaf5821ee46 | cirros-0.3.4-x86_64-uec-ramdisk | ari         | ari              | 3740163   | active | f98b9727094d40c78b1ed40e3bc91e80 |
| f14d6ee3-9e53-4f22-ba42-44e95810c294 | fedora-atomic-latest            | qcow2       | bare             | 507928064 | active | f98b9727094d40c78b1ed40e3bc91e80 |
+--------------------------------------+---------------------------------+-------------+------------------+-----------+--------+----------------------------------+
</pre></div>
</div>
<p>To list the available commands and resources for magnum, use:</p>
<div class="highlight-python"><div class="highlight"><pre><span></span>magnum help
</pre></div>
</div>
<p>To list out the health of the internal services, namely conductor, of magnum,
use:</p>
<div class="highlight-python"><div class="highlight"><pre><span></span>magnum service-list

+----+---------------------------------------+------------------+-------+----------+-----------------+---------------------------+---------------------------+
| id | host                                  | binary           | state | disabled | disabled_reason | created_at                | updated_at                |
+----+---------------------------------------+------------------+-------+----------+-----------------+---------------------------+---------------------------+
| 1  | oxy-dev.hq1-0a5a3c02.hq1.abcde.com    | magnum-conductor | up    |          | -               | 2016-08-31T10:03:36+00:00 | 2016-08-31T10:11:41+00:00 |
+----+---------------------------------------+------------------+-------+----------+-----------------+---------------------------+---------------------------+
</pre></div>
</div>
<p>Create a keypair for use with the ClusterTemplate:</p>
<div class="highlight-python"><div class="highlight"><pre><span></span>test -f ~/.ssh/id_rsa.pub || ssh-keygen -t rsa -N &quot;&quot; -f ~/.ssh/id_rsa
nova keypair-add --pub-key ~/.ssh/id_rsa.pub testkey
</pre></div>
</div>
<p>Check a dns server can resolve a host name properly:</p>
<div class="highlight-python"><div class="highlight"><pre><span></span>dig &lt;server name&gt; @&lt;dns server&gt; +short
</pre></div>
</div>
<p>For example:</p>
<div class="highlight-python"><div class="highlight"><pre><span></span>$ dig www.openstack.org @8.8.8.8 +short
www.openstack.org.cdn.cloudflare.net.
104.20.64.68
104.20.65.68
</pre></div>
</div>
</div>
<div class="section" id="building-a-kubernetes-cluster-based-on-fedora-atomic">
<h2>Building a Kubernetes Cluster - Based on Fedora Atomic<a class="headerlink" href="#building-a-kubernetes-cluster-based-on-fedora-atomic" title="Permalink to this headline">¶</a></h2>
<p>Create a ClusterTemplate. This is similar in nature to a flavor and describes
to magnum how to construct the cluster. The ClusterTemplate specifies a Fedora
Atomic image so the clusters which use this ClusterTemplate will be based on
Fedora Atomic. The COE (Container Orchestration Engine) and keypair need to
be specified as well:</p>
<div class="highlight-python"><div class="highlight"><pre><span></span>magnum cluster-template-create --name k8s-cluster-template \
                       --image fedora-atomic-latest \
                       --keypair testkey \
                       --external-network public \
                       --dns-nameserver 8.8.8.8 \
                       --flavor m1.small \
                       --docker-volume-size 5 \
                       --network-driver flannel \
                       --coe kubernetes
</pre></div>
</div>
<p>Create a cluster. Use the ClusterTemplate name as a template for cluster
creation. This cluster will result in one master kubernetes node and one minion
node:</p>
<div class="highlight-python"><div class="highlight"><pre><span></span>magnum cluster-create --name k8s-cluster \
                      --cluster-template k8s-cluster-template \
                      --node-count 1
</pre></div>
</div>
<p>Clusters will have an initial status of CREATE_IN_PROGRESS.  Magnum will update
the status to CREATE_COMPLETE when it is done creating the cluster.  Do not
create containers, pods, services, or replication controllers before magnum
finishes creating the cluster. They will likely not be created, and may cause
magnum to become confused.</p>
<p>The existing clusters can be listed as follows:</p>
<div class="highlight-python"><div class="highlight"><pre><span></span>magnum cluster-list

+--------------------------------------+-------------+------------+--------------+-----------------+
| uuid                                 | name        | node_count | master_count | status          |
+--------------------------------------+-------------+------------+--------------------------------+
| 9dccb1e6-02dc-4e2b-b897-10656c5339ce | k8s-cluster | 1          | 1            | CREATE_COMPLETE |
+--------------------------------------+-------------+------------+--------------+-----------------+
</pre></div>
</div>
<p>More detailed information for a given cluster is obtained via:</p>
<div class="highlight-python"><div class="highlight"><pre><span></span>magnum cluster-show k8s-cluster
</pre></div>
</div>
<p>After a cluster is created, you can dynamically add/remove node(s) to/from the
cluster by updating the node_count attribute. For example, to add one more
node:</p>
<div class="highlight-python"><div class="highlight"><pre><span></span>magnum cluster-update k8s-cluster replace node_count=2
</pre></div>
</div>
<p>Clusters in the process of updating will have a status of UPDATE_IN_PROGRESS.
Magnum will update the status to UPDATE_COMPLETE when it is done updating
the cluster.</p>
<p><strong>NOTE:</strong> Reducing node_count will remove all the existing pods on the nodes
that are deleted. If you choose to reduce the node_count, magnum will first
try to remove empty nodes with no pods running on them. If you reduce
node_count by more than the number of empty nodes, magnum must remove nodes
that have running pods on them. This action will delete those pods. We
strongly recommend using a replication controller before reducing the
node_count so any removed pods can be automatically recovered on your
remaining nodes.</p>
<p>Heat can be used to see detailed information on the status of a stack or
specific cluster:</p>
<p>To check the list of all cluster stacks:</p>
<div class="highlight-python"><div class="highlight"><pre><span></span>openstack stack list
</pre></div>
</div>
<p>To check an individual cluster&#8217;s stack:</p>
<div class="highlight-python"><div class="highlight"><pre><span></span>openstack stack show &lt;stack-name or stack_id&gt;
</pre></div>
</div>
<p>Monitoring cluster status in detail (e.g., creating, updating):</p>
<div class="highlight-python"><div class="highlight"><pre><span></span>CLUSTER_HEAT_NAME=$(openstack stack list | \
                    awk &quot;/\sk8s-cluster-/{print \$4}&quot;)
echo ${CLUSTER_HEAT_NAME}
openstack stack resource list ${CLUSTER_HEAT_NAME}
</pre></div>
</div>
</div>
<div class="section" id="building-a-kubernetes-cluster-based-on-coreos">
<h2>Building a Kubernetes Cluster - Based on CoreOS<a class="headerlink" href="#building-a-kubernetes-cluster-based-on-coreos" title="Permalink to this headline">¶</a></h2>
<p>You can create a Kubernetes cluster based on CoreOS as an alternative to
Atomic. First, download the official CoreOS image:</p>
<div class="highlight-python"><div class="highlight"><pre><span></span>wget http://beta.release.core-os.net/amd64-usr/current/coreos_production_openstack_image.img.bz2
bunzip2 coreos_production_openstack_image.img.bz2
</pre></div>
</div>
<p>Upload the image to glance:</p>
<div class="highlight-python"><div class="highlight"><pre><span></span>glance image-create --name CoreOS  \
                    --visibility public \
                    --disk-format=qcow2 \
                    --container-format=bare \
                    --os-distro=coreos \
                    --file=coreos_production_openstack_image.img
</pre></div>
</div>
<p>Create a CoreOS Kubernetes ClusterTemplate, which is similar to the Atomic
Kubernetes ClusterTemplate, except for pointing to a different image:</p>
<div class="highlight-python"><div class="highlight"><pre><span></span>magnum cluster-template-create --name k8s-cluster-template-coreos \
                       --image CoreOS \
                       --keypair testkey \
                       --external-network public \
                       --dns-nameserver 8.8.8.8 \
                       --flavor m1.small \
                       --network-driver flannel \
                       --coe kubernetes
</pre></div>
</div>
<p>Create a CoreOS Kubernetes cluster. Use the CoreOS ClusterTemplate as a
template for cluster creation:</p>
<div class="highlight-python"><div class="highlight"><pre><span></span>magnum cluster-create --name k8s-cluster \
                  --cluster-template k8s-cluster-template-coreos \
                  --node-count 2
</pre></div>
</div>
</div>
<div class="section" id="using-a-kubernetes-cluster">
<h2>Using a Kubernetes Cluster<a class="headerlink" href="#using-a-kubernetes-cluster" title="Permalink to this headline">¶</a></h2>
<p><strong>NOTE:</strong> For the following examples, only one minion node is required in the
k8s cluster created previously.</p>
<p>Kubernetes provides a number of examples you can use to check that things are
working. You may need to download kubectl binary for interacting with k8s
cluster using:</p>
<div class="highlight-python"><div class="highlight"><pre><span></span>curl -LO https://storage.googleapis.com/kubernetes-release/release/v1.2.0/bin/linux/amd64/kubectl
chmod +x ./kubectl
sudo mv ./kubectl /usr/local/bin/kubectl
</pre></div>
</div>
<p>We first need to setup the certs to allow Kubernetes to authenticate our
connection.   Please refer to
<a class="reference external" href="http://docs.openstack.org/developer/magnum/userguide.html#transport-layer-security">http://docs.openstack.org/developer/magnum/userguide.html#transport-layer-security</a>
for more info on using TLS keys/certs which are setup below.</p>
<p>To generate an RSA key, you will use the &#8216;genrsa&#8217; command of the &#8216;openssl&#8217;
tool.:</p>
<div class="highlight-python"><div class="highlight"><pre><span></span>openssl genrsa -out client.key 4096
</pre></div>
</div>
<p>To generate a CSR for client authentication, openssl requires a config file
that specifies a few values.:</p>
<div class="highlight-python"><div class="highlight"><pre><span></span>$ cat &gt; client.conf &lt;&lt; END
[req]
distinguished_name = req_distinguished_name
req_extensions     = req_ext
prompt = no
[req_distinguished_name]
CN = Your Name
[req_ext]
extendedKeyUsage = clientAuth
END
</pre></div>
</div>
<p>Once you have client.conf, you can run the openssl &#8216;req&#8217; command to generate
the CSR.:</p>
<div class="highlight-python"><div class="highlight"><pre><span></span>openssl req -new -days 365 \
    -config client.conf \
    -key client.key \
    -out client.csr
</pre></div>
</div>
<p>Now that you have your client CSR, you can use the Magnum CLI to send it off
to Magnum to get it signed and also download the signing cert.:</p>
<div class="highlight-python"><div class="highlight"><pre><span></span>magnum ca-sign --cluster k8s-cluster --csr client.csr &gt; client.crt
magnum ca-show --cluster k8s-cluster &gt; ca.crt
</pre></div>
</div>
<p>Here&#8217;s how to set up the replicated redis example. Now we create a pod for the
redis-master:</p>
<div class="highlight-python"><div class="highlight"><pre><span></span># Using cluster-config command for faster configuration
eval $(magnum cluster-config k8s-cluster)

# Test the cert and connection works
kubectl version

cd kubernetes/examples/redis
kubectl create -f ./redis-master.yaml
</pre></div>
</div>
<p>Now create a service to provide a discoverable endpoint for the redis
sentinels in the cluster:</p>
<div class="highlight-python"><div class="highlight"><pre><span></span>kubectl create -f ./redis-sentinel-service.yaml
</pre></div>
</div>
<p>To make it a replicated redis cluster create replication controllers for the
redis slaves and sentinels:</p>
<div class="highlight-python"><div class="highlight"><pre><span></span>sed -i &#39;s/\(replicas: \)1/\1 2/&#39; redis-controller.yaml
kubectl create -f ./redis-controller.yaml

sed -i &#39;s/\(replicas: \)1/\1 2/&#39; redis-sentinel-controller.yaml
kubectl create -f ./redis-sentinel-controller.yaml
</pre></div>
</div>
<p>Full lifecycle and introspection operations for each object are supported.
For example, magnum cluster-create, magnum cluster-template-delete.</p>
<p>Now there are four redis instances (one master and three slaves) running
across the cluster, replicating data between one another.</p>
<p>Run the cluster-show command to get the IP of the cluster host on which the
redis-master is running:</p>
<div class="highlight-python"><div class="highlight"><pre><span></span>magnum cluster-show k8s-cluster

+--------------------+------------------------------------------------------------+
| Property           | Value                                                      |
+--------------------+------------------------------------------------------------+
| status             | CREATE_COMPLETE                                            |
| uuid               | cff82cd0-189c-4ede-a9cb-2c0af6997709                       |
| stack_id           | 7947844a-8e18-4c79-b591-ecf0f6067641                       |
| status_reason      | Stack CREATE completed successfully                        |
| created_at         | 2016-05-26T17:45:57+00:00                                  |
| updated_at         | 2016-05-26T17:50:02+00:00                                  |
| create_timeout     | 60                                                         |
| api_address        | https://172.24.4.4:6443                                    |
| coe_version        | v1.2.0                                                     |
| cluster_template_id| e73298e7-e621-4d42-b35b-7a1952b97158                       |
| master_addresses   | [&#39;172.24.4.6&#39;]                                             |
| node_count         | 1                                                          |
| node_addresses     | [&#39;172.24.4.5&#39;]                                             |
| master_count       | 1                                                          |
| container_version  | 1.9.1                                                      |
| discovery_url      | https://discovery.etcd.io/4caaa65f297d4d49ef0a085a7aecf8e0 |
| name               | k8s-cluster                                                |
+--------------------+------------------------------------------------------------+
</pre></div>
</div>
<p>The output here indicates the redis-master is running on the cluster host with
IP address 172.24.4.5. To access the redis master:</p>
<div class="highlight-python"><div class="highlight"><pre><span></span>ssh fedora@172.24.4.5
REDIS_ID=$(sudo docker ps | grep redis:v1 | grep k8s_master | awk &#39;{print $1}&#39;)
sudo docker exec -i -t $REDIS_ID redis-cli

127.0.0.1:6379&gt; set replication:test true
OK
^D

exit  # Log out of the host
</pre></div>
</div>
<p>Log into one of the other container hosts and access a redis slave from it.
You can use <cite>nova list</cite> to enumerate the kube-minions. For this example we
will use the same host as above:</p>
<div class="highlight-python"><div class="highlight"><pre><span></span>ssh fedora@172.24.4.5
REDIS_ID=$(sudo docker ps | grep redis:v1 | grep k8s_redis | awk &#39;{print $1}&#39;)
sudo docker exec -i -t $REDIS_ID redis-cli

127.0.0.1:6379&gt; get replication:test
&quot;true&quot;
^D

exit  # Log out of the host
</pre></div>
</div>
<p>Additional useful commands from a given minion:</p>
<div class="highlight-python"><div class="highlight"><pre><span></span>sudo docker ps  # View Docker containers on this minion
kubectl get pods  # Get pods
kubectl get rc  # Get replication controllers
kubectl get svc  # Get services
kubectl get nodes  # Get nodes
</pre></div>
</div>
<p>After you finish using the cluster, you want to delete it. A cluster can be
deleted as follows:</p>
<div class="highlight-python"><div class="highlight"><pre><span></span>magnum cluster-delete k8s-cluster
</pre></div>
</div>
</div>
<div class="section" id="building-and-using-a-swarm-cluster">
<h2>Building and Using a Swarm Cluster<a class="headerlink" href="#building-and-using-a-swarm-cluster" title="Permalink to this headline">¶</a></h2>
<p>Create a ClusterTemplate. It is very similar to the Kubernetes ClusterTemplate,
except for the absence of some Kubernetes-specific arguments and the use of
&#8216;swarm&#8217; as the COE:</p>
<div class="highlight-python"><div class="highlight"><pre><span></span>magnum cluster-template-create --name swarm-cluster-template \
                       --image fedora-atomic-latest \
                       --keypair testkey \
                       --external-network public \
                       --dns-nameserver 8.8.8.8 \
                       --flavor m1.small \
                       --docker-volume-size 5 \
                       --coe swarm
</pre></div>
</div>
<p><strong>NOTE:</strong> If you are using Magnum behind a firewall then refer
to <a class="reference external" href="http://docs.openstack.org/developer/magnum/magnum-proxy.html">http://docs.openstack.org/developer/magnum/magnum-proxy.html</a></p>
<p>Finally, create the cluster. Use the ClusterTemplate &#8216;swarm-cluster-template&#8217;
as a template for cluster creation. This cluster will result in one swarm
manager node and two extra agent nodes:</p>
<div class="highlight-python"><div class="highlight"><pre><span></span>magnum cluster-create --name swarm-cluster \
                      --cluster-template swarm-cluster-template \
                      --node-count 2
</pre></div>
</div>
<p>Now that we have a swarm cluster we can start interacting with it:</p>
<div class="highlight-python"><div class="highlight"><pre><span></span>magnum cluster-show swarm-cluster

+--------------------+------------------------------------------------------------+
| Property           | Value                                                      |
+--------------------+------------------------------------------------------------+
| status             | CREATE_COMPLETE                                            |
| uuid               | eda91c1e-6103-45d4-ab09-3f316310fa8e                       |
| stack_id           | 7947844a-8e18-4c79-b591-ecf0f6067641                       |
| status_reason      | Stack CREATE completed successfully                        |
| created_at         | 2015-04-20T19:05:27+00:00                                  |
| updated_at         | 2015-04-20T19:06:08+00:00                                  |
| create_timeout     | 60                                                         |
| api_address        | https://172.24.4.4:6443                                    |
| coe_version        | 1.2.5                                                      |
| cluster_template_id| e73298e7-e621-4d42-b35b-7a1952b97158                       |
| master_addresses   | [&#39;172.24.4.6&#39;]                                             |
| node_count         | 2                                                          |
| node_addresses     | [&#39;172.24.4.5&#39;]                                             |
| master_count       | 1                                                          |
| container_version  | 1.9.1                                                      |
| discovery_url      | https://discovery.etcd.io/4caaa65f297d4d49ef0a085a7aecf8e0 |
| name               | swarm-cluster                                              |
+--------------------+------------------------------------------------------------+
</pre></div>
</div>
<p>We now need to setup the docker CLI to use the swarm cluster we have created
with the appropriate credentials.</p>
<p>Create a dir to store certs and cd into it. The <cite>DOCKER_CERT_PATH</cite> env variable
is consumed by docker which expects ca.pem, key.pem and cert.pem to be in that
directory.:</p>
<div class="highlight-python"><div class="highlight"><pre><span></span>export DOCKER_CERT_PATH=~/.docker
mkdir -p ${DOCKER_CERT_PATH}
cd ${DOCKER_CERT_PATH}
</pre></div>
</div>
<p>Generate an RSA key.:</p>
<div class="highlight-python"><div class="highlight"><pre><span></span>openssl genrsa -out key.pem 4096
</pre></div>
</div>
<p>Create openssl config to help generated a CSR.:</p>
<div class="highlight-python"><div class="highlight"><pre><span></span>$ cat &gt; client.conf &lt;&lt; END
[req]
distinguished_name = req_distinguished_name
req_extensions     = req_ext
prompt = no
[req_distinguished_name]
CN = Your Name
[req_ext]
extendedKeyUsage = clientAuth
END
</pre></div>
</div>
<p>Run the openssl &#8216;req&#8217; command to generate the CSR.:</p>
<div class="highlight-python"><div class="highlight"><pre><span></span>openssl req -new -days 365 \
    -config client.conf \
    -key key.pem \
    -out client.csr
</pre></div>
</div>
<p>Now that you have your client CSR use the Magnum CLI to get it signed and also
download the signing cert.:</p>
<div class="highlight-python"><div class="highlight"><pre><span></span>magnum ca-sign --cluster swarm-cluster --csr client.csr &gt; cert.pem
magnum ca-show --cluster swarm-cluster &gt; ca.pem
</pre></div>
</div>
<p>Set the CLI to use TLS . This env var is consumed by docker.:</p>
<div class="highlight-python"><div class="highlight"><pre><span></span>export DOCKER_TLS_VERIFY=&quot;1&quot;
</pre></div>
</div>
<p>Set the correct host to use which is the public ip address of swarm API server
endpoint. This env var is consumed by docker.:</p>
<div class="highlight-python"><div class="highlight"><pre><span></span>export DOCKER_HOST=$(magnum cluster-show swarm-cluster | awk &#39;/ api_address /{print substr($4,7)}&#39;)
</pre></div>
</div>
<p>Next we will create a container in this swarm cluster. This container will ping
the address 8.8.8.8 four times:</p>
<div class="highlight-python"><div class="highlight"><pre><span></span>docker run --rm -it cirros:latest ping -c 4 8.8.8.8
</pre></div>
</div>
<p>You should see a similar output to:</p>
<div class="highlight-python"><div class="highlight"><pre><span></span>PING 8.8.8.8 (8.8.8.8): 56 data bytes
64 bytes from 8.8.8.8: seq=0 ttl=40 time=25.513 ms
64 bytes from 8.8.8.8: seq=1 ttl=40 time=25.348 ms
64 bytes from 8.8.8.8: seq=2 ttl=40 time=25.226 ms
64 bytes from 8.8.8.8: seq=3 ttl=40 time=25.275 ms

--- 8.8.8.8 ping statistics ---
4 packets transmitted, 4 packets received, 0% packet loss
round-trip min/avg/max = 25.226/25.340/25.513 ms
</pre></div>
</div>
</div>
<div class="section" id="building-and-using-a-mesos-cluster">
<h2>Building and Using a Mesos Cluster<a class="headerlink" href="#building-and-using-a-mesos-cluster" title="Permalink to this headline">¶</a></h2>
<p>Provisioning a mesos cluster requires a Ubuntu-based image with some packages
pre-installed. To build and upload such image, please refer to
<a class="reference external" href="http://docs.openstack.org/developer/magnum/userguide.html#building-mesos-image">http://docs.openstack.org/developer/magnum/userguide.html#building-mesos-image</a></p>
<p>Alternatively, you can download and upload a pre-built image:</p>
<div class="highlight-python"><div class="highlight"><pre><span></span>wget https://fedorapeople.org/groups/magnum/ubuntu-mesos-latest.qcow2
glance image-create --name ubuntu-mesos --visibility public \
                    --disk-format=qcow2 --container-format=bare \
                    --os-distro=ubuntu --file=ubuntu-mesos-latest.qcow2
</pre></div>
</div>
<p>Then, create a ClusterTemplate by using &#8216;mesos&#8217; as the COE, with the rest of
arguments similar to the Kubernetes ClusterTemplate:</p>
<div class="highlight-python"><div class="highlight"><pre><span></span>magnum cluster-template-create --name mesos-cluster-template --image ubuntu-mesos \
                       --keypair testkey \
                       --external-network public \
                       --dns-nameserver 8.8.8.8 \
                       --flavor m1.small \
                       --coe mesos
</pre></div>
</div>
<p>Finally, create the cluster. Use the ClusterTemplate &#8216;mesos-cluster-template&#8217;
as a template for cluster creation. This cluster will result in one mesos
master node and two mesos slave nodes:</p>
<div class="highlight-python"><div class="highlight"><pre><span></span>magnum cluster-create --name mesos-cluster \
                      --cluster-template mesos-cluster-template \
                      --node-count 2
</pre></div>
</div>
<p>Now that we have a mesos cluster we can start interacting with it. First we
need to make sure the cluster&#8217;s status is &#8216;CREATE_COMPLETE&#8217;:</p>
<div class="highlight-python"><div class="highlight"><pre><span></span>$ magnum cluster-show mesos-cluster

+--------------------+------------------------------------------------------------+
| Property           | Value                                                      |
+--------------------+------------------------------------------------------------+
| status             | CREATE_COMPLETE                                            |
| uuid               | ff727f0d-72ca-4e2b-9fef-5ec853d74fdf                       |
| stack_id           | 7947844a-8e18-4c79-b591-ecf0f6067641                       |
| status_reason      | Stack CREATE completed successfully                        |
| created_at         | 2015-06-09T20:21:43+00:00                                  |
| updated_at         | 2015-06-09T20:28:18+00:00                                  |
| create_timeout     | 60                                                         |
| api_address        | https://172.24.4.115:6443                                  |
| coe_version        | -                                                          |
| cluster_template_id| 92dbda62-32d4-4435-88fc-8f42d514b347                       |
| master_addresses   | [&#39;172.24.4.115&#39;]                                           |
| node_count         | 2                                                          |
| node_addresses     | [&#39;172.24.4.116&#39;, &#39;172.24.4.117&#39;]                           |
| master_count       | 1                                                          |
| container_version  | 1.9.1                                                      |
| discovery_url      | None                                                       |
| name               | mesos-cluster                                              |
+--------------------+------------------------------------------------------------+
</pre></div>
</div>
<p>Next we will create a container in this cluster by using the REST API of
Marathon. This container will ping the address 8.8.8.8:</p>
<div class="highlight-python"><div class="highlight"><pre><span></span>$ cat &gt; mesos.json &lt;&lt; END
{
  &quot;container&quot;: {
    &quot;type&quot;: &quot;DOCKER&quot;,
    &quot;docker&quot;: {
      &quot;image&quot;: &quot;cirros&quot;
    }
  },
  &quot;id&quot;: &quot;ubuntu&quot;,
  &quot;instances&quot;: 1,
  &quot;cpus&quot;: 0.5,
  &quot;mem&quot;: 512,
  &quot;uris&quot;: [],
  &quot;cmd&quot;: &quot;ping 8.8.8.8&quot;
}
END
$ MASTER_IP=$(magnum cluster-show mesos-cluster | awk &#39;/ api_address /{print $4}&#39;)
$ curl -X POST -H &quot;Content-Type: application/json&quot; \
    http://${MASTER_IP}:8080/v2/apps -d@mesos.json
</pre></div>
</div>
<p>To check application and task status:</p>
<div class="highlight-python"><div class="highlight"><pre><span></span>$ curl http://${MASTER_IP}:8080/v2/apps
$ curl http://${MASTER_IP}:8080/v2/tasks
</pre></div>
</div>
<p>You can access to the Mesos web page at http://&lt;master&gt;:5050/ and Marathon web
console at http://&lt;master&gt;:8080/.</p>
</div>
<div class="section" id="building-developer-documentation">
<h2>Building Developer Documentation<a class="headerlink" href="#building-developer-documentation" title="Permalink to this headline">¶</a></h2>
<p>To build the documentation locally (e.g., to test documentation changes
before uploading them for review) chdir to the magnum root folder and
run tox:</p>
<div class="highlight-python"><div class="highlight"><pre><span></span><span class="n">tox</span> <span class="o">-</span><span class="n">edocs</span>
</pre></div>
</div>
<p><strong>NOTE:</strong> The first time you run this will take some extra time as it
creates a virtual environment to run in.</p>
<p>When complete, the documentation can be accessed from:</p>
<div class="highlight-python"><div class="highlight"><pre><span></span><span class="n">doc</span><span class="o">/</span><span class="n">build</span><span class="o">/</span><span class="n">html</span><span class="o">/</span><span class="n">index</span><span class="o">.</span><span class="n">html</span>
</pre></div>
</div>
</div>
</div>


          </div>
        </div>
      </div>
<div class="sphinxsidebar">
    <div class="sphinxsidebarwrapper">
            <h3><a href="../index.html">Table Of Contents</a></h3>
            <ul>
<li><a class="reference internal" href="#">Developer Quick-Start</a><ul>
<li><a class="reference internal" href="#setup-dev-environment">Setup Dev Environment</a></li>
<li><a class="reference internal" href="#exercising-the-services-using-devstack">Exercising the Services Using Devstack</a></li>
<li><a class="reference internal" href="#building-a-kubernetes-cluster-based-on-fedora-atomic">Building a Kubernetes Cluster - Based on Fedora Atomic</a></li>
<li><a class="reference internal" href="#building-a-kubernetes-cluster-based-on-coreos">Building a Kubernetes Cluster - Based on CoreOS</a></li>
<li><a class="reference internal" href="#using-a-kubernetes-cluster">Using a Kubernetes Cluster</a></li>
<li><a class="reference internal" href="#building-and-using-a-swarm-cluster">Building and Using a Swarm Cluster</a></li>
<li><a class="reference internal" href="#building-and-using-a-mesos-cluster">Building and Using a Mesos Cluster</a></li>
<li><a class="reference internal" href="#building-developer-documentation">Building Developer Documentation</a></li>
</ul>
</li>
</ul>

            <h4>Previous topic</h4>
            <p class="topless"><a href="../index.html"
                                  title="previous chapter">Welcome to Magnum&#8217;s Developer Documentation!</a></p>
            <h4>Next topic</h4>
            <p class="topless"><a href="cluster-type-definition.html"
                                  title="next chapter">Cluster Type Definition</a></p>
            <h3>Project Source</h3>
            <ul class="this-page-menu">
              <li><a href="http://git.openstack.org/cgit/openstack/magnum
"
                     rel="nofollow">Project Source</a></li>
            </ul>
            <h3>This Page</h3>
            <ul class="this-page-menu">
              <li><a href="../_sources/dev/quickstart.txt"
                     rel="nofollow">Show Source</a></li>
            </ul>
          <div id="searchbox" style="display: none">
            <h3>Quick search</h3>
              <form class="search" action="../search.html" method="get">
                <input type="text" name="q" size="18" />
                <input type="submit" value="Go" />
                <input type="hidden" name="check_keywords" value="yes" />
                <input type="hidden" name="area" value="default" />
              </form>
              <p class="searchtip" style="font-size: 90%">
              Enter search terms or a module, class or function name.
              </p>
          </div>
          <script type="text/javascript">$('#searchbox').show(0);</script>
    </div>
</div>

      <div class="clearer"></div>
    </div>
    <div class="related" role="navigation" aria-label="related navigation">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="../genindex.html" title="General Index"
             accesskey="I">index</a></li>
        <li class="right" >
          <a href="cluster-type-definition.html" title="Cluster Type Definition"
             accesskey="N">next</a> |</li>
        <li class="right" >
          <a href="../index.html" title="Welcome to Magnum’s Developer Documentation!"
             accesskey="P">previous</a> |</li>
        <li class="nav-item nav-item-0"><a href="../index.html">magnum 4.0.1.dev40 documentation</a> &raquo;</li> 
      </ul>
    </div>

    <div class="footer" role="contentinfo">
        &copy; Copyright 2013, OpenStack Foundation.
      Created using <a href="http://sphinx-doc.org/">Sphinx</a> 1.3.6.
    </div>
<script type="text/javascript">
var gaJsHost = (("https:" == document.location.protocol) ? "https://ssl." : "http://www.");
document.write(unescape("%3Cscript src='" + gaJsHost + "google-analytics.com/ga.js' type='text/javascript'%3E%3C/script%3E"));
</script>
<script type="text/javascript">
try {
//Tracking docs.openstack.org/developer/<projectname> only
//The URL is built from the project variable in conf.py
var pageTracker = _gat._getTracker("UA-17511903-1");
pageTracker._setCookiePath("/developer/magnum");
pageTracker._trackPageview();
} catch(err) {}</script>

  </body>
</html>