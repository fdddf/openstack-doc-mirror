<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN"
  "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">


<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    
    <title>Bare Metal Instances in Overcloud &mdash; tripleo-docs 0.0.1.dev344 documentation</title>
    
    <link rel="stylesheet" href="../_static/nature.css" type="text/css" />
    <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
    <link rel="stylesheet" href="../_static/custom.css" type="text/css" />
    <link rel="stylesheet" href="../_static/tweaks.css" type="text/css" />
    
    <script type="text/javascript">
      var DOCUMENTATION_OPTIONS = {
        URL_ROOT:    '../',
        VERSION:     '0.0.1.dev344',
        COLLAPSE_INDEX: false,
        FILE_SUFFIX: '.html',
        HAS_SOURCE:  true
      };
    </script>
    <script type="text/javascript" src="../_static/jquery.js"></script>
    <script type="text/javascript" src="../_static/underscore.js"></script>
    <script type="text/javascript" src="../_static/doctools.js"></script>
    <script type="text/javascript" src="../_static/cookies.js"></script>
    <script type="text/javascript" src="../_static/expandable.js"></script>
    <script type="text/javascript" src="../_static/admonition_selector.js"></script>
    <script type="text/javascript" src="../_static/jquery.scrollTo.js"></script>
    <script type="text/javascript" src="../_static/jquery.nav.js"></script>
    <script type="text/javascript" src="../_static/menu.js"></script>
    <link rel="top" title="tripleo-docs 0.0.1.dev344 documentation" href="../index.html" />
    <link rel="up" title="Feature Configuration" href="features.html" />
    <link rel="next" title="Deploying with OVS DPDK Support" href="ovs_dpdk_config.html" />
    <link rel="prev" title="Configuring High Availability" href="high_availability.html" /> 
  </head>
  <body>
  <div id="header">
    <h1 id="logo"><a href="http://www.openstack.org/">OpenStack</a></h1>
    <ul id="navigation">
      
      <li><a href="http://www.openstack.org/" title="Go to the Home page" class="link">Home</a></li>
      <li><a href="http://www.openstack.org/projects/" title="Go to the OpenStack Projects page">Projects</a></li>
      <li><a href="http://www.openstack.org/user-stories/" title="Go to the User Stories page" class="link">User Stories</a></li>
      <li><a href="http://www.openstack.org/community/" title="Go to the Community page" class="link">Community</a></li>
      <li><a href="http://www.openstack.org/blog/" title="Go to the OpenStack Blog">Blog</a></li>
      <li><a href="http://wiki.openstack.org/" title="Go to the OpenStack Wiki">Wiki</a></li>
      <li><a href="http://docs.openstack.org/" title="Go to OpenStack Documentation" class="current">Documentation</a></li>
      
    </ul>
  </div>
  

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          <div class="body">
            
  <div class="section" id="bare-metal-instances-in-overcloud">
<h1>Bare Metal Instances in Overcloud<a class="headerlink" href="#bare-metal-instances-in-overcloud" title="Permalink to this headline">¶</a></h1>
<p>This documentation explains installing Ironic for providing bare metal
instances in the overcloud to end users. This feature is supported starting
with Newton.</p>
<p>You need at least 3 nodes to use bare metal provisioning: one for the
undercloud, one for the controller and one for the actual instance.
This guide assumes using both virtual and bare metal computes, so to follow it
you need at least one more node, 4 in total.</p>
<p>It is recommended to have at least 12 GiB of RAM on the undercloud and
at least 8 GiB of RAM on the controllers. The controllers should have enough
disk space to keep a cache of user instance images, at least 50 GiB is
recommended.</p>
<p>It&#8217;s also highly recommended that you use at least two networks:</p>
<ul class="simple">
<li>Undercloud provisioning network (connects undercloud and overcloud nodes)</li>
<li>Overcloud provisioning network (connects overcloud nodes and tenant bare
metal instances)</li>
</ul>
<p>This guide, however, uses one network for simplicity. If you encounter weird
DHCP, PXE or networking issues with such a single-network configuration, try
shutting down the introspection DHCP server on the undercloud after the initial
introspection is finished:</p>
<div class="highlight-python"><div class="highlight"><pre><span></span>sudo systemctl stop openstack-ironic-inspector-dnsmasq
</pre></div>
</div>
<div class="section" id="preparing-environment">
<h2>Preparing environment<a class="headerlink" href="#preparing-environment" title="Permalink to this headline">¶</a></h2>
<p>If you already have an <tt class="docutils literal"><span class="pre">instackenv.json</span></tt> file with all nodes prepared, you
might want to leave some of the nodes for overcloud instances. E.g. if you have
three nodes in the <tt class="docutils literal"><span class="pre">instackenv.json</span></tt>, you can split them:</p>
<div class="highlight-python"><div class="highlight"><pre><span></span>jq &#39;.nodes[0:2] | {nodes: .}&#39; instackenv.json &gt; undercloud.json
</pre></div>
</div>
<p>The format of the remaining nodes is TripleO-specific, so we need
to convert it to something Ironic can understand without using
TripleO workflows:</p>
<div class="highlight-python"><div class="highlight"><pre><span></span>jq &#39;.nodes[2:3] | {nodes: map({driver: .pm_type, name: .name,
    driver_info: {ssh_username: .pm_user, ssh_address: .pm_addr,
                  ssh_key_contents: .pm_password, ssh_virt_type: &quot;virsh&quot;},
    properties: {cpus: .cpu, cpu_arch: .arch, local_gb: .disk, memory_mb: .memory},
    ports: .mac | map({address: .})})}&#39; instackenv.json &gt; overcloud-nodes.yaml
</pre></div>
</div>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p class="last">This command intentionally omits the capabilities, as they are often
TripleO-specific, e.g. they force local boot instead of network boot used
by default in Ironic.</p>
</div>
<p>Then enroll only <tt class="docutils literal"><span class="pre">undercloud.json</span></tt> in your undercloud:</p>
<div class="highlight-python"><div class="highlight"><pre><span></span>source stackrc
openstack overcloud node import --provide undercloud.json
</pre></div>
</div>
<div class="stable admonition">
<p class="first admonition-title">Stable Branch</p>
<div class="mitaka last admonition">
<p class="first admonition-title">Mitaka</p>
<p>For TripleO release Mitaka, the nodes should be imported with:</p>
<div class="last highlight-python"><div class="highlight"><pre><span></span>openstack baremetal import undercloud.json
</pre></div>
</div>
</div>
</div>
<div class="virtual admonition">
<p class="first admonition-title">Virtual</p>
<p class="last">If you used <strong>tripleo-quickstart</strong>, you may have to delete the nodes that
did not end up in undercloud.json.</p>
</div>
</div>
<div class="section" id="configuring-and-deploying-overcloud">
<h2>Configuring and deploying overcloud<a class="headerlink" href="#configuring-and-deploying-overcloud" title="Permalink to this headline">¶</a></h2>
<p>A few things can be configured in advance for overcloud Ironic in an
environment file (<tt class="docutils literal"><span class="pre">ironic-config.yaml</span></tt> in this guide):</p>
<ul>
<li><p class="first"><tt class="docutils literal"><span class="pre">IronicEnabledDrivers</span></tt> parameter sets the list of enabled drivers.
The most often used bare metal driver is <tt class="docutils literal"><span class="pre">pxe_ipmitool</span></tt>. Also enabled
by default are <tt class="docutils literal"><span class="pre">pxe_ilo</span></tt> and <tt class="docutils literal"><span class="pre">pxe_drac</span></tt> drivers.</p>
<p>Other drivers might require additional configuration to work properly.
See <a class="reference external" href="http://docs.openstack.org/developer/ironic/deploy/drivers.html">Ironic drivers documentation</a> for
details.</p>
<div class="virtual admonition">
<p class="first admonition-title">Virtual</p>
<p>Testing on a virtual environment requires the <tt class="docutils literal"><span class="pre">pxe_ssh</span></tt> driver to be
explicitly enabled, for example:</p>
<div class="highlight-python"><div class="highlight"><pre><span></span>parameter_defaults:
    IronicEnabledDrivers:
        - pxe_ssh
</pre></div>
</div>
<p>If you used <strong>tripleo-quickstart</strong> to build your environment, the
resulting configuration is a bit different:</p>
<div class="last highlight-python"><div class="highlight"><pre><span></span>parameter_defaults:
    IronicEnabledDrivers:
        - pxe_ssh
    ControllerExtraConfig:
        ironic::drivers::ssh::libvirt_uri: &#39;qemu:///session&#39;
</pre></div>
</div>
</div>
</li>
<li><p class="first"><tt class="docutils literal"><span class="pre">NovaSchedulerDefaultFilters</span></tt> configures available
scheduler filters. For a hybrid deployment it&#8217;s important to prepend
<tt class="docutils literal"><span class="pre">AggregateInstanceExtraSpecsFilter</span></tt> to the default list:</p>
<div class="highlight-python"><div class="highlight"><pre><span></span>parameter_defaults:
    NovaSchedulerDefaultFilters:
        - RetryFilter
        - AggregateInstanceExtraSpecsFilter
        - AvailabilityZoneFilter
        - RamFilter
        - DiskFilter
        - ComputeFilter
        - ComputeCapabilitiesFilter
        - ImagePropertiesFilter
</pre></div>
</div>
<p>For a deployment with <strong>only</strong> bare metal hosts you might want to replace
some filters with their <tt class="docutils literal"><span class="pre">Exact</span></tt> counterparts. In such case the scheduler
will require a strict match between bare metal nodes and flavors. Otherwise,
any bare metal node with higher or equal specs would match.</p>
<div class="highlight-python"><div class="highlight"><pre><span></span>parameter_defaults:
    NovaSchedulerDefaultFilters:
        - RetryFilter
        - AvailabilityZoneFilter
        - ExactRamFilter
        - ExactDiskFilter
        - ExactCoreFilter
        - ComputeFilter
        - ComputeCapabilitiesFilter
        - ImagePropertiesFilter
</pre></div>
</div>
</li>
<li><p class="first"><tt class="docutils literal"><span class="pre">IronicCleaningDiskErase</span></tt> configures erasing hard drives
before the first and after every deployment. There are two recommended
values: <tt class="docutils literal"><span class="pre">full</span></tt> erases all data and <tt class="docutils literal"><span class="pre">metadata</span></tt> erases only disk metadata.
The former is more secure, the latter is faster.</p>
<div class="virtual admonition">
<p class="first admonition-title">Virtual</p>
<p class="last">It is highly recommended to set this parameter to <tt class="docutils literal"><span class="pre">metadata</span></tt>
for virtual environments, as full cleaning can be extremely slow there.</p>
</div>
</li>
<li><p class="first"><tt class="docutils literal"><span class="pre">IronicCleaningNetwork</span></tt> sets the name or UUID of the <strong>overcloud</strong> network
to use for node cleaning. Initially is set to <tt class="docutils literal"><span class="pre">provisioning</span></tt> and should be
set to an actual UUID later when <a class="reference internal" href="#configuring-cleaning">Configuring cleaning</a>.</p>
<div class="newton admonition">
<p class="first admonition-title">Newton</p>
<p class="last">In the Newton release this parameter was not available, and no default
value was set for the cleaning network.</p>
</div>
</li>
<li><p class="first"><tt class="docutils literal"><span class="pre">IronicIPXEEnabled</span></tt> parameter turns on iPXE (HTTP-based) for deployment
instead of PXE (TFTP-based). iPXE is more reliable and scales better, so
it&#8217;s on by default. Also iPXE is required for UEFI boot support.</p>
</li>
</ul>
<p>Add the ironic environment file when deploying:</p>
<div class="highlight-python"><div class="highlight"><pre><span></span>openstack overcloud deploy --templates \
    -e /usr/share/openstack-tripleo-heat-templates/environments/services/ironic.yaml \
    -e ironic-config.yaml
</pre></div>
</div>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p class="last">We don&#8217;t require any virtual compute nodes for the bare metal only case,
so feel free to set <tt class="docutils literal"><span class="pre">ComputeCount:</span> <span class="pre">0</span></tt> in your environment file, if you
don&#8217;t need them.</p>
</div>
<div class="section" id="checking-deployment">
<h3>Checking deployment<a class="headerlink" href="#checking-deployment" title="Permalink to this headline">¶</a></h3>
<p>Check that Ironic works by connecting to the overcloud and trying to list the
nodes (you should see an empty response, but not an error):</p>
<div class="highlight-python"><div class="highlight"><pre><span></span>source overcloudrc
openstack baremetal node list
</pre></div>
</div>
<p>You can also check the enabled driver list:</p>
<div class="highlight-python"><div class="highlight"><pre><span></span>$ openstack baremetal driver list
+---------------------+-------------------------+
| Supported driver(s) | Active host(s)          |
+---------------------+-------------------------+
| pxe_drac            | overcloud-controller-0. |
| pxe_ilo             | overcloud-controller-0. |
| pxe_ipmitool        | overcloud-controller-0. |
+---------------------+-------------------------+
</pre></div>
</div>
<p>For HA configuration you should see all three controllers:</p>
<div class="highlight-python"><div class="highlight"><pre><span></span>$ openstack baremetal driver list
+---------------------+------------------------------------------------------------------------------------------------------------+
| Supported driver(s) | Active host(s)                                                                                             |
+---------------------+------------------------------------------------------------------------------------------------------------+
| pxe_drac            | overcloud-controller-0.localdomain, overcloud-controller-1.localdomain, overcloud-controller-2.localdomain |
| pxe_ilo             | overcloud-controller-0.localdomain, overcloud-controller-1.localdomain, overcloud-controller-2.localdomain |
| pxe_ipmitool        | overcloud-controller-0.localdomain, overcloud-controller-1.localdomain, overcloud-controller-2.localdomain |
+---------------------+------------------------------------------------------------------------------------------------------------+
</pre></div>
</div>
<p>If this list is empty or does not show any of the controllers, then the
<tt class="docutils literal"><span class="pre">openstack-ironic-conductor</span></tt> service on this controller failed to start.
The likely cause is missing dependencies for vendor drivers.</p>
</div>
<div class="section" id="preparing-networking">
<h3>Preparing networking<a class="headerlink" href="#preparing-networking" title="Permalink to this headline">¶</a></h3>
<p>Next, we need to create at least one network for nodes to use. By default
Ironic uses the tenant network for the provisioning process, and the same
network is often configured for cleaning. Using separate networks is beyond
the scope of this guide.</p>
<p>As already mentioned, this guide assumes only one physical network shared
between undercloud and overcloud. In this case the subnet address must match
the one on the undercloud, but the allocation pools must not overlap (including
the pool used by undercloud introspection).</p>
<p>For example, the following commands will work with the default undercloud
parameters:</p>
<div class="highlight-python"><div class="highlight"><pre><span></span>source overcloudrc
openstack network create --share --provider-network-type flat \
    --provider-physical-network datacentre --external provisioning
openstack subnet create --network provisioning \
    --subnet-range 192.168.24.0/24 --gateway 192.168.24.40 \
    --allocation-pool start=192.168.24.41,end=192.168.24.100 provisioning-subnet
</pre></div>
</div>
<div class="admonition warning">
<p class="first admonition-title">Warning</p>
<p class="last">Network types other than &#8220;flat&#8221; are not supported.</p>
</div>
<p>We will use this network for bare metal instances (both for provisioning and
as a tenant network), as well as an external network for virtual instances.
In a real situation you will only use it as provisioning, and create a separate
physical network as external.</p>
<p>Now you can create a regular tenant network to use for virtual instances
and a router between provisioning and tenant networks:</p>
<div class="highlight-python"><div class="highlight"><pre><span></span>openstack network create tenant-net
openstack subnet create --network tenant-net --subnet-range 192.0.3.0/24 \
    --allocation-pool start=192.0.3.10,end=192.0.3.20 tenant-subnet
openstack router create default-router
openstack router add subnet default-router provisioning-subnet
openstack router add subnet default-router tenant-subnet
</pre></div>
</div>
</div>
<div class="section" id="configuring-cleaning">
<h3>Configuring cleaning<a class="headerlink" href="#configuring-cleaning" title="Permalink to this headline">¶</a></h3>
<p>Starting with the Ocata release, Ironic is configured to use network called
<tt class="docutils literal"><span class="pre">provisioning</span></tt> for node cleaning. However, network names are not unique.
A user creating another network with the same name will break bare metal
provisioning. Thus, it&#8217;s highly recommended to update the deployment,
providing the provider network UUID.</p>
<p>Use the following command to get the UUID:</p>
<div class="highlight-python"><div class="highlight"><pre><span></span>openstack network show provisioning -f value -c id
</pre></div>
</div>
<p>Update the environment file you&#8217;ve created, setting <tt class="docutils literal"><span class="pre">IronicCleaningNetwork</span></tt>
to the this UUID, for example:</p>
<div class="highlight-python"><div class="highlight"><pre><span></span>parameter_defaults:
    IronicCleaningNetwork: c71f4bfe-409b-4292-818f-21cdf910ee06
</pre></div>
</div>
<div class="newton admonition">
<p class="first admonition-title">Newton</p>
<p>In the Newton release this parameter was not available, use
<tt class="docutils literal"><span class="pre">cleaning_network_uuid</span></tt> hieradata value instead, for example:</p>
<div class="highlight-python"><div class="highlight"><pre><span></span>parameter_defaults:
    ControllerExtraConfig:
        ironic::conductor::cleaning_network_uuid: c71f4bfe-409b-4292-818f-21cdf910ee06
</pre></div>
</div>
<p class="last">This variable does not support node names and does not have a default value
in this release.</p>
</div>
<p>Finally, run the deploy command with exactly the same arguments as before
(don&#8217;t forget to include the environment file if it was not included
previously).</p>
</div>
<div class="section" id="adding-deployment-images">
<h3>Adding deployment images<a class="headerlink" href="#adding-deployment-images" title="Permalink to this headline">¶</a></h3>
<p>Ironic requires the ironic-python-agent image stored in Glance.
You can use the same images you already have on the undercloud:</p>
<div class="highlight-python"><div class="highlight"><pre><span></span>source overcloudrc
openstack image create --public --container-format aki \
    --disk-format aki --file ~/ironic-python-agent.kernel deploy-kernel
openstack image create --public --container-format ari \
    --disk-format ari --file ~/ironic-python-agent.initramfs deploy-ramdisk
</pre></div>
</div>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p class="last">These commands assume that the images are in the home directory, which is
often the case for TripleO.</p>
</div>
</div>
<div class="section" id="creating-flavors-and-host-aggregates">
<h3>Creating flavors and host aggregates<a class="headerlink" href="#creating-flavors-and-host-aggregates" title="Permalink to this headline">¶</a></h3>
<p>As usual with OpenStack, you need to create at least one flavor to be used
during deployment. As bare metal resources are inherently not divisible,
the flavor will set minimum requirements (CPU count, RAM and disk sizes) that
a node must fulfil. Creating a single flavor is sufficient for the
simplest case:</p>
<div class="highlight-python"><div class="highlight"><pre><span></span>source overcloudrc
openstack flavor create --ram 1024 --disk 20 --vcpus 1 baremetal
</pre></div>
</div>
<p>If you don&#8217;t plan on using virtual instances, this is where you can stop.</p>
<p>For a hybrid bare metal and virtual environment, you have to set up <em>host
aggregates</em> for virtual and bare metal hosts. We will use a property
called <tt class="docutils literal"><span class="pre">baremetal</span></tt> to link flavors to host aggregates:</p>
<div class="highlight-python"><div class="highlight"><pre><span></span>openstack aggregate create --property baremetal=true baremetal-hosts
openstack aggregate create --property baremetal=false virtual-hosts
openstack flavor set baremetal --property baremetal=true
</pre></div>
</div>
<div class="admonition warning">
<p class="first admonition-title">Warning</p>
<p class="last">This association won&#8217;t work without <tt class="docutils literal"><span class="pre">AggregateInstanceExtraSpecsFilter</span></tt>
enabled as described in <a class="reference internal" href="#configuring-and-deploying-overcloud">Configuring and deploying overcloud</a>.</p>
</div>
<p>Then for all flavors you&#8217;ve created for virtual instances set the same
<tt class="docutils literal"><span class="pre">baremetal</span></tt> property to <tt class="docutils literal"><span class="pre">false</span></tt>, for example:</p>
<div class="highlight-python"><div class="highlight"><pre><span></span>openstack flavor create --ram 1024 --disk 20 --vcpus 1 virtual
openstack flavor set virtual --property baremetal=false
</pre></div>
</div>
</div>
<div class="section" id="creating-instance-images">
<h3>Creating instance images<a class="headerlink" href="#creating-instance-images" title="Permalink to this headline">¶</a></h3>
<p>You can build your images using <tt class="docutils literal"><span class="pre">diskimage-builder</span></tt> tool already available
on the undercloud, for example:</p>
<div class="highlight-python"><div class="highlight"><pre><span></span>disk-image-create centos7 baremetal dhcp-all-interfaces grub2 -o centos-image
</pre></div>
</div>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p>The following elements are actually optional:</p>
<ul class="last simple">
<li><tt class="docutils literal"><span class="pre">dhcp-all-interfaces</span></tt> makes the resulting instance get IP addresses for
all NICs via DHCP.</li>
<li><tt class="docutils literal"><span class="pre">grub2</span></tt> installs the grub bootloader on the image, so that local boot
can be used in additional to PXE booting.</li>
</ul>
</div>
<p>This command creates a so called <em>partition image</em>, i.e. an image containing
only root partition. Ironic also supports <em>whole disk images</em>, i.e. images
with the whole partition table embedded. This may be the only option when
running non-Linux images. Please check <a class="reference external" href="http://docs.openstack.org/developer/ironic/deploy/install-guide.html#image-requirements">Ironic images documentation</a>
for more details on building and using images.</p>
<p>Three components are created for every partition image: the main image with
<tt class="docutils literal"><span class="pre">qcow2</span></tt> extension, the kernel with <tt class="docutils literal"><span class="pre">vmlinuz</span></tt> extension and the initrd
image with <tt class="docutils literal"><span class="pre">initrd</span></tt> extension.</p>
<p>Upload them with the following command:</p>
<div class="highlight-python"><div class="highlight"><pre><span></span>source overcloudrc
KERNEL_ID=$(openstack image create --file centos-image.vmlinuz --public \
    --container-format aki --disk-format aki -f value -c id \
    centos-image.vmlinuz)
RAMDISK_ID=$(openstack image create --file centos-image.initrd --public \
    --container-format ari --disk-format ari -f value -c id \
    centos-image.initrd)
openstack image create --file centos-image.qcow2 --public \
    --container-format bare --disk-format qcow2 \
    --property kernel_id=$KERNEL_ID --property ramdisk_id=$RAMDISK_ID \
    centos-image
</pre></div>
</div>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p class="last">A whole disk image will only have one component - the image itself with
<tt class="docutils literal"><span class="pre">qcow2</span></tt> extension. Do not set <tt class="docutils literal"><span class="pre">kernel_id</span></tt> and <tt class="docutils literal"><span class="pre">ramdisk_id</span></tt>
properties for such images.</p>
</div>
</div>
</div>
<div class="section" id="enrolling-nodes">
<h2>Enrolling nodes<a class="headerlink" href="#enrolling-nodes" title="Permalink to this headline">¶</a></h2>
<p>For all nodes you&#8217;re enrolling you need to know:</p>
<ul class="simple">
<li>BMC (IPMI, iDRAC, iLO, etc) address and credentials,</li>
<li>MAC address of the PXE booting NIC,</li>
<li>CPU count and architecture, memory size in MiB and root disk size in GiB,</li>
<li>Serial number or WWN of the root device, if the node has several hard drives.</li>
</ul>
<p>In the future some of this data will be provided by the introspection process,
which is not currently available in the overcloud.</p>
<p>This guide uses inventory files to enroll nodes. Alternatively, you can enroll
nodes directly from CLI, see <a class="reference external" href="http://docs.openstack.org/developer/ironic/deploy/install-guide.html#enrollment">Ironic enrollment documentation</a>
for details.</p>
<div class="section" id="preparing-inventory">
<h3>Preparing inventory<a class="headerlink" href="#preparing-inventory" title="Permalink to this headline">¶</a></h3>
<p>If you have not prepared <tt class="docutils literal"><span class="pre">overcloud-nodes.yaml</span></tt> while <a class="reference internal" href="#preparing-environment">Preparing
environment</a>, do it now in the following format:</p>
<div class="highlight-python"><div class="highlight"><pre><span></span>nodes:
    - name: node-0
      driver: pxe_ipmitool
      driver_info:
        ipmi_address: &lt;BMC HOST&gt;
        ipmi_username: &lt;BMC USER&gt;
        ipmi_password: &lt;BMC PASSWORD&gt;
      properties:
        cpus: &lt;CPU COUNT&gt;
        cpu_arch: &lt;CPU ARCHITECTURE&gt;
        memory_mb: &lt;MEMORY IN MIB&gt;
        local_gb: &lt;ROOT DISK IN GIB&gt;
        root_device:
            serial: &lt;ROOT DISK SERIAL&gt;
      ports:
        - address: &lt;PXE NIC MAC&gt;
</pre></div>
</div>
<p>The <tt class="docutils literal"><span class="pre">driver</span></tt> field must be one of <tt class="docutils literal"><span class="pre">IronicEnabledDrivers</span></tt>, which we set
when <a class="reference internal" href="#configuring-and-deploying-overcloud">Configuring and deploying overcloud</a>.</p>
<p>The <tt class="docutils literal"><span class="pre">root_device</span></tt> property is optional, but it&#8217;s highly recommended
to set it if the bare metal node has more than one hard drive.
There are several properties that can be used instead of the serial number
to designate the root device, see <a class="reference external" href="http://docs.openstack.org/developer/ironic/deploy/install-guide.html#specifying-the-disk-for-deployment">Ironic root device hints documentation</a>
for details.</p>
</div>
<div class="section" id="id1">
<h3>Enrolling nodes<a class="headerlink" href="#id1" title="Permalink to this headline">¶</a></h3>
<p>The <tt class="docutils literal"><span class="pre">overcloud-nodes.yaml</span></tt> file prepared in the previous steps can now be
imported in Ironic:</p>
<div class="highlight-python"><div class="highlight"><pre><span></span>export OS_BAREMETAL_API_VERSION=1.11
source overcloudrc
openstack baremetal create overcloud-nodes.yaml
</pre></div>
</div>
<div class="admonition warning">
<p class="first admonition-title">Warning</p>
<p class="last">This command is provided by Ironic, not TripleO. It also does not feature
support for updates, so if you need to change something, you have to use
<tt class="docutils literal"><span class="pre">openstack</span> <span class="pre">baremetal</span> <span class="pre">node</span> <span class="pre">set</span></tt> and similar commands.</p>
</div>
<p>The nodes appear in the <tt class="docutils literal"><span class="pre">enroll</span></tt> provision state, you need to check their BMC
credentials and make them available:</p>
<div class="highlight-python"><div class="highlight"><pre><span></span>DEPLOY_KERNEL=$(openstack image show deploy-kernel -f value -c id)
DEPLOY_RAMDISK=$(openstack image show deploy-ramdisk -f value -c id)

for uuid in $(openstack baremetal node list -f value -c UUID);
do
    openstack baremetal node manage $uuid
    openstack baremetal node set $uuid \
        --driver-info deploy_kernel=$DEPLOY_KERNEL \
        --driver-info deploy_ramdisk=$DEPLOY_RAMDISK
    openstack baremetal node provide $uuid
done
</pre></div>
</div>
<p>The deploy kernel and ramdisk were created as part of <a class="reference internal" href="#adding-deployment-images">Adding deployment
images</a>.</p>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p class="last">The <tt class="docutils literal"><span class="pre">baremetal</span> <span class="pre">node</span> <span class="pre">provide</span></tt> command makes a node go through cleaning
procedure, so it might take some time depending on the configuration.</p>
</div>
<p>If a node gets stuck in the <tt class="docutils literal"><span class="pre">enroll</span></tt> state, and you see the following error:</p>
<div class="highlight-python"><div class="highlight"><pre><span></span>The requested action &quot;provide&quot; can not be performed on node &quot;&lt;UUID&gt;&quot; while it is in state &quot;enroll&quot;.
</pre></div>
</div>
<p>then the power credentials validation failed for this node. Use the following
command to get the last error:</p>
<div class="highlight-python"><div class="highlight"><pre><span></span>openstack baremetal node show &lt;UUID&gt; -f value -c last_error
</pre></div>
</div>
</div>
<div class="section" id="checking-available-resources">
<h3>Checking available resources<a class="headerlink" href="#checking-available-resources" title="Permalink to this headline">¶</a></h3>
<p>Check that nodes are really enrolled and the power state is reflected correctly
(it may take some time):</p>
<div class="highlight-python"><div class="highlight"><pre><span></span>$ source overcloudrc
$ openstack baremetal node list
+--------------------------------------+------------+---------------+-------------+--------------------+-------------+
| UUID                                 | Name       | Instance UUID | Power State | Provisioning State | Maintenance |
+--------------------------------------+------------+---------------+-------------+--------------------+-------------+
| a970c5db-67dd-4676-95ba-af1edc74b2ee | instance-0 | None          | power off   | available          | False       |
| bd99ec64-4bfc-491b-99e6-49bd384b526d | instance-1 | None          | power off   | available          | False       |
+--------------------------------------+------------+---------------+-------------+--------------------+-------------+
</pre></div>
</div>
<p>After a few minutes, new hypervisors should appear in Nova and the stats
should display the sum of bare metal and virtual resources:</p>
<div class="highlight-python"><div class="highlight"><pre><span></span>$ openstack hypervisor list
+----+--------------------------------------+
| ID | Hypervisor Hostname                  |
+----+--------------------------------------+
|  2 | overcloud-novacompute-0.localdomain  |
| 17 | bd99ec64-4bfc-491b-99e6-49bd384b526d |
| 20 | a970c5db-67dd-4676-95ba-af1edc74b2ee |
+----+--------------------------------------+

$ openstack hypervisor stats show
+----------------------+-------+
| Field                | Value |
+----------------------+-------+
| count                | 3     |
| current_workload     | 0     |
| disk_available_least | 146   |
| free_disk_gb         | 149   |
| free_ram_mb          | 16047 |
| local_gb             | 149   |
| local_gb_used        | 0     |
| memory_mb            | 18095 |
| memory_mb_used       | 2048  |
| running_vms          | 0     |
| vcpus                | 3     |
| vcpus_used           | 0     |
+----------------------+-------+
</pre></div>
</div>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p class="last">Each bare metal node becomes a separate hypervisor in Nova. The hypervisor
host name always matches the associated node UUID.</p>
</div>
</div>
<div class="section" id="assigning-host-aggregates">
<h3>Assigning host aggregates<a class="headerlink" href="#assigning-host-aggregates" title="Permalink to this headline">¶</a></h3>
<p>For hybrid bare metal and virtual case you need to specify which host belongs
to which host aggregates (<tt class="docutils literal"><span class="pre">virtual</span></tt> or <tt class="docutils literal"><span class="pre">baremetal</span></tt> as created in
<a class="reference internal" href="#creating-flavors-and-host-aggregates">Creating flavors and host aggregates</a>).</p>
<p>When the default host names are used, we can take advantage of the fact
that every virtual host will have <tt class="docutils literal"><span class="pre">compute</span></tt> in its name. All bare metal
hypervisors will be assigned to one (non-HA) or three (HA) controller hosts.
So we can do the assignment with the following commands:</p>
<div class="highlight-python"><div class="highlight"><pre><span></span>source overcloudrc
for vm_host in $(openstack hypervisor list -f value -c &quot;Hypervisor Hostname&quot; | grep compute);
do
    openstack aggregate add host virtual-hosts $vm_host
done

openstack aggregate add host baremetal-hosts overcloud-controller-0.localdomain
# Ignore the following two for a non-HA environment
openstack aggregate add host baremetal-hosts overcloud-controller-1.localdomain
openstack aggregate add host baremetal-hosts overcloud-controller-2.localdomain
</pre></div>
</div>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p class="last">Every time you scale out compute nodes, you need to add newly added hosts
to the <tt class="docutils literal"><span class="pre">virtual-hosts</span></tt> aggregate.</p>
</div>
</div>
</div>
<div class="section" id="booting-a-bare-metal-instance">
<h2>Booting a bare metal instance<a class="headerlink" href="#booting-a-bare-metal-instance" title="Permalink to this headline">¶</a></h2>
<p>You will probably want to create a keypair to use for logging into instances.
For example, using SSH public key from undercloud:</p>
<div class="highlight-python"><div class="highlight"><pre><span></span>source overcloudrc
openstack keypair create --public-key ~/.ssh/id_rsa.pub undercloud-key
</pre></div>
</div>
<p>Now you&#8217;re ready to boot your first bare metal instance:</p>
<div class="highlight-python"><div class="highlight"><pre><span></span>openstack server create --image centos-image --flavor baremetal \
    --nic net-id=$(openstack network show provisioning -f value -c id) \
    --key-name undercloud-key instance-0
</pre></div>
</div>
<p>After some time (depending on the image), you will see the prepared instance:</p>
<div class="highlight-python"><div class="highlight"><pre><span></span>$ openstack server list
+--------------------------------------+------------+--------+-----------------------------+
| ID                                   | Name       | Status | Networks                    |
+--------------------------------------+------------+--------+-----------------------------+
| 2022d237-e249-44bd-b864-e7f536a8e439 | instance-0 | ACTIVE | provisioning=192.168.24.50  |
+--------------------------------------+------------+--------+-----------------------------+
</pre></div>
</div>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p class="last">If you encounter <em>&#8220;No valid host found&#8221;</em> error from Nova, make sure to read
the undercloud troubleshooting guide on this topic: <a class="reference internal" href="../troubleshooting/troubleshooting-overcloud.html#no-valid-host"><em>No Valid Host Found Error</em></a>.</p>
</div>
<p>Let&#8217;s check that it actually got scheduled on a bare metal machine:</p>
<div class="highlight-python"><div class="highlight"><pre><span></span>$ openstack server show instance-0 -c &quot;OS-EXT-SRV-ATTR:host&quot; -c &quot;OS-EXT-SRV-ATTR:hypervisor_hostname&quot;
+-------------------------------------+--------------------------------------+
| Field                               | Value                                |
+-------------------------------------+--------------------------------------+
| OS-EXT-SRV-ATTR:host                | overcloud-controller-0.localdomain   |
| OS-EXT-SRV-ATTR:hypervisor_hostname | bd99ec64-4bfc-491b-99e6-49bd384b526d |
+-------------------------------------+--------------------------------------+
</pre></div>
</div>
<p>You can now log into it:</p>
<div class="highlight-python"><div class="highlight"><pre><span></span>$ ssh centos@192.168.24.50
The authenticity of host &#39;192.168.24.50 (192.168.24.50)&#39; can&#39;t be established.
ECDSA key fingerprint is eb:35:45:c5:ed:d9:8a:e8:4b:20:db:06:10:6f:05:74.
Are you sure you want to continue connecting (yes/no)? yes
Warning: Permanently added &#39;192.168.24.50&#39; (ECDSA) to the list of known hosts.
[centos@instance-0 ~]$
</pre></div>
</div>
<p>Now let&#8217;s try the same with a virtual instance:</p>
<div class="highlight-python"><div class="highlight"><pre><span></span>openstack server create --image centos-image --flavor virtual \
    --nic net-id=$(openstack network show tenant-net -f value -c id) \
    --key-name undercloud-key instance-1
</pre></div>
</div>
<p>This instance gets scheduled on a virtual host:</p>
<div class="highlight-python"><div class="highlight"><pre><span></span>$ openstack server show instance-1 -c &quot;OS-EXT-SRV-ATTR:host&quot; -c &quot;OS-EXT-SRV-ATTR:hypervisor_hostname&quot;
+-------------------------------------+-------------------------------------+
| Field                               | Value                               |
+-------------------------------------+-------------------------------------+
| OS-EXT-SRV-ATTR:host                | overcloud-novacompute-0.localdomain |
| OS-EXT-SRV-ATTR:hypervisor_hostname | overcloud-novacompute-0.localdomain |
+-------------------------------------+-------------------------------------+
</pre></div>
</div>
</div>
</div>


          </div>
        </div>
      </div>
<div class="sphinxsidebar">
    <div class="sphinxsidebarwrapper">
            <h3><a href="../index.html">Table Of Contents</a></h3>
            <ul>
<li><a class="reference internal" href="#">Bare Metal Instances in Overcloud</a><ul>
<li><a class="reference internal" href="#preparing-environment">Preparing environment</a></li>
<li><a class="reference internal" href="#configuring-and-deploying-overcloud">Configuring and deploying overcloud</a><ul>
<li><a class="reference internal" href="#checking-deployment">Checking deployment</a></li>
<li><a class="reference internal" href="#preparing-networking">Preparing networking</a></li>
<li><a class="reference internal" href="#configuring-cleaning">Configuring cleaning</a></li>
<li><a class="reference internal" href="#adding-deployment-images">Adding deployment images</a></li>
<li><a class="reference internal" href="#creating-flavors-and-host-aggregates">Creating flavors and host aggregates</a></li>
<li><a class="reference internal" href="#creating-instance-images">Creating instance images</a></li>
</ul>
</li>
<li><a class="reference internal" href="#enrolling-nodes">Enrolling nodes</a><ul>
<li><a class="reference internal" href="#preparing-inventory">Preparing inventory</a></li>
<li><a class="reference internal" href="#id1">Enrolling nodes</a></li>
<li><a class="reference internal" href="#checking-available-resources">Checking available resources</a></li>
<li><a class="reference internal" href="#assigning-host-aggregates">Assigning host aggregates</a></li>
</ul>
</li>
<li><a class="reference internal" href="#booting-a-bare-metal-instance">Booting a bare metal instance</a></li>
</ul>
</li>
</ul>

            <h4>Previous topic</h4>
            <p class="topless"><a href="high_availability.html"
                                  title="previous chapter">Configuring High Availability</a></p>
            <h4>Next topic</h4>
            <p class="topless"><a href="ovs_dpdk_config.html"
                                  title="next chapter">Deploying with OVS DPDK Support</a></p>
            <h3>Project Source</h3>
            <ul class="this-page-menu">
              <li><a href="http://git.openstack.org/cgit/openstack/tripleo-docs
"
                     rel="nofollow">Project Source</a></li>
            </ul>
            <h3>This Page</h3>
            <ul class="this-page-menu">
              <li><a href="../_sources/advanced_deployment/baremetal_overcloud.txt"
                     rel="nofollow">Show Source</a></li>
            </ul>
  <div id="admonition_selector">
    <span class="trigger">Limit Environment Specific Content</span>

    <div class="content">
      <span class="title">Operating Systems</span>
      <ul>
        <li><input type="checkbox" id="centos" checked="checked"><label for="centos" title="Step that should only be run when using CentOS.">CentOS</label></li>
        <li><input type="checkbox" id="rhel" checked="checked"><label for="rhel" title="Step that should only be run when using RHEL.">RHEL</label></li>
      </ul>

      <span class="title">Branches</span>
      <ul>
        <li><input type="checkbox" id="stable" checked=""><label for="stable" title="Step that should only be run when choosing to use components from their stable branches rather than using packages/source based on current master.">Install from stable branch</label></li>
        <li><input type="checkbox" id="mitaka" checked=""><label for="mitaka" title="Step that should only be run when installing from the Mitaka stable branch.">Install from Mitaka branch</label></li>
        <li><input type="checkbox" id="newton" checked=""><label for="newton" title="Step that should only be run when installing from the Newton stable branch.">Install from Newton branch</label></li>
      </ul>

      <span class="title">RHEL Registration Types</span>
      <ul>
        <li><input type="checkbox" id="portal" checked="checked"><label for="portal" title="Step that should only be run when registering to the Red Hat Portal.">Portal</label></li>
        <li><input type="checkbox" id="satellite" checked="checked"><label for="satellite" title="Step that should only be run when registering to Red Hat Satellite.">Satellite</label></li>
      </ul>

      <span class="title">Environments</span>
      <ul>
        <li><input type="checkbox" id="baremetal" checked="checked"><label for="baremetal" title="Step that should only be run when deploying to baremetal.">Baremetal</label></li>
        <li><input type="checkbox" id="virtual" checked="checked"><label for="virtual" title="Step that should only be run when deploying to virtual machines.">Virtual</label></li>
        <li><input type="checkbox" id="ssl" checked="checked"><label for="ssl" title="Step that should only be run when deploying with SSL OpenStack endpoints.">SSL</label></li>
        <li><input type="checkbox" id="selfsigned" checked="checked"><label for="selfsigned" title="Step that should only be run when deploying with SSL and a self-signed certificate.">Self-Signed SSL</label></li>
      </ul>

      <span class="title">Additional Overcloud Roles</span>
      <ul>
        <li><input type="checkbox" id="ceph" checked="checked"><label for="ceph" title="Step that should only be run when deploying Ceph for use by the Overcloud.">Ceph</label></li>
      </ul>

      <span class="title">Development options</span>
      <ul>
         <li><input type="checkbox" id="source" checked=""><label for="source"
            title="Step that should only be run when choosing to use some components directly from their git source code repositories instead of packages.">Install from source</label></li>
      </ul>

      <span class="title">Upgrade Version</span>
      <ul>
        <li><input type="checkbox" id="ktol" checked="checked"><label for="ktol" title="Upgrading Kilo to Liberty is not supported">Upgrading Kilo to Liberty (unsupported)</label></li>
        <li><input type="checkbox" id="ltom" checked="checked"><label for="ltom" title="Step that should only be run for upgrading from Liberty to Mitaka">Upgrading Liberty to Mitaka</label></li>
        <li><input type="checkbox" id="mton" checked="checked"><label for="mton" title="Step that should only be run for upgrading from Mitaka to Newton">Upgrading Mitaka to Newton</label></li>
      </ul>


    </div>
  </div>

  
          <div id="searchbox" style="display: none">
            <h3>Quick search</h3>
              <form class="search" action="../search.html" method="get">
                <input type="text" name="q" size="18" />
                <input type="submit" value="Go" />
                <input type="hidden" name="check_keywords" value="yes" />
                <input type="hidden" name="area" value="default" />
              </form>
              <p class="searchtip" style="font-size: 90%">
              Enter search terms or a module, class or function name.
              </p>
          </div>
          <script type="text/javascript">$('#searchbox').show(0);</script>

    </div>
</div>

      <div class="clearer"></div>
    </div>
    <div class="related">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="../genindex.html" title="General Index"
             accesskey="I">index</a></li>
        <li class="right" >
          <a href="ovs_dpdk_config.html" title="Deploying with OVS DPDK Support"
             accesskey="N">next</a> |</li>
        <li class="right" >
          <a href="high_availability.html" title="Configuring High Availability"
             accesskey="P">previous</a> |</li>
        <li><a href="../index.html">tripleo-docs 0.0.1.dev344 documentation</a> &raquo;</li>
          <li><a href="features.html" accesskey="U">Feature Configuration</a> &raquo;</li> 
      </ul>
    </div>

    <div class="footer">
        &copy; Copyright 2015, OpenStack Foundation.
      Created using <a href="http://sphinx-doc.org/">Sphinx</a> 1.2.3.
    </div>
<script type="text/javascript">
var gaJsHost = (("https:" == document.location.protocol) ? "https://ssl." : "http://www.");
document.write(unescape("%3Cscript src='" + gaJsHost + "google-analytics.com/ga.js' type='text/javascript'%3E%3C/script%3E"));
</script>
<script type="text/javascript">
try {
//Tracking docs.openstack.org/developer/<projectname> only
//The URL is built from the project variable in conf.py
var pageTracker = _gat._getTracker("UA-17511903-1");
pageTracker._setCookiePath("/developer/tripleo-docs");
pageTracker._trackPageview();
} catch(err) {}</script>

  </body>
</html>